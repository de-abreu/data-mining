{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87afd18e-e584-4013-82ed-a1a4b634d313",
   "metadata": {},
   "source": [
    "# Geração de Databases com SQLalchemy e PosgreSQL\n",
    "\n",
    "O presente notebook demonstra a construção de bancos de dados (BD) SQL locais a partir do uso das ferramentas SQLalchemy e PostgreSQL, para fins de realização de uma análise exploratória de dados descritos em arquivos CSV. Para tal, fizemos uso do dataset [Covid-19 Data Sharing](https://agencia.fapesp.br/covid-19-data-sharingbr-makes-more-datasets-available/35348) disponibilizado pela Agência FAPESP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9b06c-e869-4be2-8bf0-fe102f2229b4",
   "metadata": {},
   "source": [
    "## Autores\n",
    "\n",
    "| Nome | nUSP |\n",
    "| :--- | :--- |\n",
    "| Guilherme de Abreu Barreto | 12543033 |\n",
    "| Lucas Eduardo Gulka Pulcinelli | 12547336 |\n",
    "| Vinicio Yusuke Hayashibara | 13642797 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41057348-ac0e-4d5b-81cc-62dd8887391c",
   "metadata": {},
   "source": [
    "## Configuração\n",
    "\n",
    "É necessário o ao correto funcionamento deste projeto possuir uma instalação local de PostgreSQL e atribuir os valores correspondentes para acesso a este nas seguintes constantes:\n",
    "\n",
    "- `DATABASE`: O nome do database onde serão carregadas as informações. Atente-se se este não corresponde ao nome de um database preexistente **ou que esteja sendo acessado**, pois este será então sobrescrito.\n",
    "\n",
    "- `USER` e `PASSWORD`: Informações de autententicação válidas e com privilégios para a criação de bancos de dados no servidor.\n",
    "\n",
    "- `HOST` e `PORT`: A URL e porta para realização do acesso ao servidor.\n",
    "\n",
    "- `BATCH_SIZE`: O número máximo de operações sobre o BD a serem realizadas conjuntamente. Recomenda-se ser em um número o qual caiba na memória RAM que você dispõe. O número abaixo foi capaz de caber confortávelmente em 10 GiB de RAM **na minha máquina**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b8964e1-6dc4-4ef8-8a8d-b26eb450dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = \"postgres\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"postgres\"\n",
    "HOST = \"postgres\"\n",
    "PORT = 5432\n",
    "BATCH_SIZE = 2 * 10**6\n",
    "\n",
    "DATABASE_URI = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}/{DATABASE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ab4f1-0fde-4be4-8f4f-10d6cf9589cb",
   "metadata": {},
   "source": [
    "## Carregamento das dependências deste projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "167791eb-294d-4435-b245-53ee89d7ba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.13/site-packages (2.9.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: sqlalchemy[postgres] in /opt/conda/lib/python3.13/site-packages (2.0.43)\n",
      "\u001b[33mWARNING: sqlalchemy 2.0.43 does not provide the extra 'postgres'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.13/site-packages (from sqlalchemy[postgres]) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.13/site-packages (from sqlalchemy[postgres]) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.13/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary sqlalchemy[postgres] tqdm pandas\n",
    "\n",
    "import enum\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from sqlalchemy import (\n",
    "    CheckConstraint as constraint,\n",
    "    Enum,\n",
    "    Date,\n",
    "    ForeignKey as fk,\n",
    "    String,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    TypeDecorator,\n",
    "    create_engine,\n",
    "    column as sql_column,\n",
    "    insert,\n",
    "    text\n",
    ")\n",
    "from sqlalchemy.orm import (\n",
    "    Mapped,\n",
    "    Session,\n",
    "    declarative_base,\n",
    "    relationship,\n",
    "    sessionmaker,\n",
    "    mapped_column as column,\n",
    "    validates,\n",
    ")\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Annotated, final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a5f36-93f6-40e9-8e22-578cad919506",
   "metadata": {},
   "source": [
    "## Funções e tipos de dados auxiliares\n",
    "\n",
    "Algumas funções e tipos de dados os quais utilizamos em nossa implementação, mas cuja funcionalidade provavelmente não será crucial ao caso geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cc12eb0-a5bf-44be-af91-cf6519e1e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backref(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(back_populates=back_populates)\n",
    "\n",
    "\n",
    "def childOf(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(\n",
    "        back_populates=back_populates,\n",
    "        cascade=\"all, delete-orphan\",\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_column_name(column_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert column name from UU_UUU_UUU format to UU_Uuu_Uuu format\n",
    "    Example: \"ID_PACIENTE\" -> \"ID_Paciente\", \"IC_SEXO\" -> \"IC_Sexo\"\n",
    "    \"\"\"\n",
    "    match column_name:\n",
    "        case \"CD_UF\":\n",
    "            return column_name\n",
    "        case \"CD_CEPREDUZIDO\":\n",
    "            return \"CD_CEPReduzido\"\n",
    "        case _:\n",
    "            parts = column_name.split(\"_\")\n",
    "            return \"_\".join(\n",
    "                [parts[0].upper()] + [part.capitalize() for part in parts[1:]]\n",
    "            )\n",
    "\n",
    "def parse_date(date_column: pd.Series) -> pd.Series:\n",
    "    return  pd.to_datetime(\n",
    "        date_column, format='%d/%m/%Y', errors='coerce'\n",
    "    )\n",
    "\n",
    "\n",
    "estados = [\n",
    "    \"AC\",  # Acre\n",
    "    \"AL\",  # Alagoas\n",
    "    \"AP\",  # Amapá\n",
    "    \"AM\",  # Amazonas\n",
    "    \"BA\",  # Bahia\n",
    "    \"CE\",  # Ceará\n",
    "    \"DF\",  # Distrito Federal\n",
    "    \"ES\",  # Espírito Santo\n",
    "    \"GO\",  # Goiás\n",
    "    \"MA\",  # Maranhão\n",
    "    \"MT\",  # Mato Grosso\n",
    "    \"MS\",  # Mato Grosso do Sul\n",
    "    \"MG\",  # Minas Gerais\n",
    "    \"PA\",  # Pará\n",
    "    \"PB\",  # Paraíba\n",
    "    \"PR\",  # Paraná\n",
    "    \"PE\",  # Pernambuco\n",
    "    \"PI\",  # Piauí\n",
    "    \"RJ\",  # Rio de Janeiro\n",
    "    \"RN\",  # Rio Grande do Norte\n",
    "    \"RS\",  # Rio Grande do Sul\n",
    "    \"RO\",  # Rondônia\n",
    "    \"RR\",  # Roraima\n",
    "    \"SC\",  # Santa Catarina\n",
    "    \"SP\",  # São Paulo\n",
    "    \"SE\",  # Sergipe\n",
    "    \"TO\",  # Tocantins\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cd4b3-b8dd-4afe-a96e-df842eecf19f",
   "metadata": {},
   "source": [
    "## Definição das tabelas comuns\n",
    "\n",
    "Abaixo descrevemos a estrutura pretendida às tabelas Pacientes, ExamLabs e Despachos, comuns a todos o BDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69ea8aa3-8ca6-42af-b523-d5b2a7791ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class PacienteBase(Base):\n",
    "    __abstract__: bool = True\n",
    "\n",
    "    IC_Sexo: Mapped[str] = column(\n",
    "        Enum('M', 'F', name='sexo_enum'),\n",
    "        comment=\"Sexo do Paciente. F - Feminino; M - Masculino\"\n",
    "    )\n",
    "    AA_Nascimento: Mapped[str | None] = column(\n",
    "        String(4),\n",
    "        comment=\"Ano de nascimento do Paciente. 4 caracteres alfanuméricos. Os 4 dígitos do ano do nascimento; ou AAAA - para ano de nascimento igual ou anterior a 1930 (visando anonimização); YYYY - quaisquer outros anos, em caso de anonimização do ano\"\n",
    "    )\n",
    "    CD_Pais: Mapped[str | None] = column(\n",
    "        String(2),\n",
    "        comment=\"Pais de residencia do Paciente. 2 caracteres alfanuméricos. BR ou XX (país estrangeiro)\"\n",
    "    )\n",
    "    CD_UF: Mapped[str | None] = column(\n",
    "        Enum(*estados, name='estado_enum'),\n",
    "        comment=\"Unidade da Federacao de residencia do Paciente. 2 caracteres alfanuméricos\"\n",
    "    )\n",
    "    CD_Municipio: Mapped[str | None] = column(\n",
    "        comment=\"Municipio de residencia do Paciente. Alfanumérico.\"\n",
    "    )\n",
    "    CD_CEPReduzido: Mapped[str | None] = column(comment=\"[Descrição não encontrada nos comentários]\")\n",
    "\n",
    "    @validates(\"AA_Nascimento\")\n",
    "    def validates_nascimento(self, _key: str, value: str) -> str:\n",
    "        match value:\n",
    "            case \"AAAA\" | \"YYYY\":\n",
    "                return value\n",
    "            case year if len(year) == 4 and year.isdigit():\n",
    "                return year\n",
    "            case _:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid AA_Nascimento value: {value}. Must be 'AAAA', 'YYYY', or a 4-digit number\"\n",
    "                )\n",
    "\n",
    "\n",
    "class Paciente(PacienteBase):\n",
    "    \"\"\"\n",
    "    Tabela de pacientes Covid-19 FAPESP\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"Pacientes\"\n",
    "\n",
    "    ID_Paciente: Mapped[str] = column(\n",
    "        primary_key=True,\n",
    "        comment=\"Identificação única do paciente (correlaciona com o ID_PACIENTE de todos os arquivos onde aparece). 32 caracteres alfanuméricos\"\n",
    "    )\n",
    "\n",
    "    # Relações\n",
    "    exames: Mapped[list[\"ExamLab\"]] = childOf(\"paciente\")\n",
    "    desfechos: Mapped[list[\"Desfecho\"]] = childOf(\"paciente\")\n",
    "\n",
    "\n",
    "\n",
    "class ExamLab(Base):\n",
    "    \"\"\"\n",
    "    Tabela de exames Covid-19 FAPESP\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"ExamLabs\"\n",
    "\n",
    "    id: Mapped[int] = column(autoincrement=True, primary_key=True)\n",
    "    ID_Paciente: Mapped[str] = column(\n",
    "        fk(\"Pacientes.ID_Paciente\"),\n",
    "        comment=\"Identificação única do paciente (correlaciona com o ID_PACIENTE de todos os arquivos onde aparece). 32 caracteres alfanuméricos\"\n",
    "    )\n",
    "    ID_Atendimento: Mapped[str | None] = column(\n",
    "        comment=\"Identificação única do atendimento. Correlaciona com o ID_ATENDIMENTO de todas as tabelas onde aparece. 32 caracteres alfanuméricos\"\n",
    "    )\n",
    "    DE_Exame: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do exame realizado. Alfanumérico. Exemplo: HEMOGRAMA, sangue total / GLICOSE, plasma / SODIO, soro / POTASSIO, soro. Um exame é composto por 1 ou mais analitos.\"\n",
    "    )\n",
    "    DE_Resultado: Mapped[str | None] = column(\n",
    "        comment=\"Resultado do exame, associado ao DE_ANALITO. Alfanumérico. Se DE_ANALITO exige valor numérico, NNNN se inteiro ou NNNN,NNN se casas decimais; Se DE_ANALITO exige qualitativo, String com domínio restrito; Se DE_ANALITO por observação microscópica, String conteúdo livre. Exemplo de dominio restrito - Positivo, Detectado, Reagente, nâo reagente, etc. Exemplo de conteúdo livre - 'não foram observados caracteres tóxico-degenerativos nos neutrófilos, não foram observadas atipias linfocitárias'\"\n",
    "    )\n",
    "    DT_Coleta: Mapped[date | None] = column(\n",
    "        comment=\"Data em que o material foi coletado do paciente\"\n",
    "    )\n",
    "    DE_Origem: Mapped[str | None] = column(\n",
    "        comment=\"Local de Coleta do exame. 4 caracteres alfabéticos: LAB – Exame realizado por paciente em uma unidade de atendimento laboratorial; HOSP – Exame realizado por paciente dentro de uma Unidade Hospitalar; UTI - exame realizado na UTI\"\n",
    "    )\n",
    "    DE_Analito: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do analito. Alfanumérico. Exemplo: Eritrócitos / Leucócitos / Glicose / Ureia / Creatinina. Para o exame Hemograma, tem o resultado de vários analitos: Eritrócitos, Hemoglobina, Leucócitos, Linfócitos, etc. A maioria dos exames tem somente 1 analito, por exemplo Glicose, Colesterol Total, Uréia e Creatinina.\"\n",
    "    )\n",
    "    CD_Unidade: Mapped[str | None] = column(\n",
    "        comment=\"Unidade de Medida utilizada na Metodologia do laboratório específico para analisar o exame. Alfanumérico. Exemplo: g/dL (gramas por decilitro)\"\n",
    "    )\n",
    "    DE_Valor_Referencia: Mapped[str | None] = column(\n",
    "        comment=\"Faixa de valores de referência. Alfanumérico. Resultado ou faixa de resultados considerado normal para este analito. Exemplo para Glicose: 75 a 99\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def DE_resultNum(self) -> float | None:\n",
    "        \"\"\"\n",
    "        Extrai valor numérico do resultado ou atribui códigos especiais para resultados textuais.\n",
    "        Baseado na lógica do script COVID19_Corrige_21_02.sql\n",
    "        \"\"\"\n",
    "        if not self.DE_Resultado:\n",
    "            return None\n",
    "\n",
    "        # Extrai valor numérico do resultado\n",
    "        numeric_match = re.search(r\"-?\\d+[,.]?\\d*\", self.DE_Resultado)\n",
    "        if numeric_match:\n",
    "            numeric_str = numeric_match.group().replace(\",\", \".\")\n",
    "            try:\n",
    "                return float(numeric_str)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # Aplica códigos especiais para exames COVID\n",
    "        if self.DE_Exame and re.search(\n",
    "            r\"(covid)|(sars.cov.2)|(corona)\", self.DE_Exame, re.IGNORECASE\n",
    "        ):\n",
    "            resultado_lower = self.DE_Resultado.lower()\n",
    "\n",
    "            if re.search(r\"detectados anticorpos\", resultado_lower):\n",
    "                return -1000.0\n",
    "            elif re.search(\n",
    "                r\"(n.o detectado)|(n.o reagente)|(negativo)|(aus.ncia de anticorpos)\",\n",
    "                resultado_lower,\n",
    "            ):\n",
    "                return -1111.0\n",
    "            elif re.search(r\"(detectado)|(reagente)|(positivo)\", resultado_lower):\n",
    "                return -1000.0\n",
    "            elif re.search(r\"(indetect.avel)|(inconclusivo)\", resultado_lower):\n",
    "                return -1234.0\n",
    "            else:\n",
    "                return -2222.0\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Relações\n",
    "    paciente: Mapped[\"Paciente\"] = backref(\"exames\")\n",
    "\n",
    "\n",
    "class Desfecho(Base):\n",
    "    \"\"\"\n",
    "    Tabela de desfechos Covid-19 FAPESP\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"Desfechos\"\n",
    "\n",
    "    ID_Paciente: Mapped[str] = column(\n",
    "        fk(\"Pacientes.ID_Paciente\"),\n",
    "        comment=\"Identificação única do paciente (correlaciona com o ID_PACIENTE de todos os arquivos onde aparece. 32 caracteres alfanuméricos)\"\n",
    "    )\n",
    "    ID_Atendimento: Mapped[str] = column(\n",
    "        comment=\"Identificação única do atendimento. Cada atendimento tem um desfecho. Correlaciona com ID_ATENDIMENTO de todas as tabelas onde aparece\"\n",
    "    )\n",
    "    DT_Atendimento: Mapped[date | None] = column(\n",
    "        comment=\"Data de realização do atendimento\"\n",
    "    )\n",
    "    DE_Tipo_Atendimento: Mapped[str] = column(\n",
    "        comment=\"Descrição do tipo de atendimento realizado. Texto livre. Exemplo: Pronto atendimento.\"\n",
    "    )\n",
    "    ID_Clinica: Mapped[int] = column(\n",
    "        comment=\"Identificação da clínica onde o evento aconteceu. Numérico. Exemplo: 1013\"\n",
    "    )\n",
    "    DE_Clinica: Mapped[str] = column(\n",
    "        comment=\"Descrição da clínica onde o evento aconteceu. Texto livre. Exemplo: Cardiologia\"\n",
    "    )\n",
    "    DT_Desfecho: Mapped[date | None] = column(\n",
    "        comment=\"Data do desfecho - Nulo se DE_DESFECHO for óbito\"\n",
    "    )\n",
    "    DE_Desfecho: Mapped[str] = column(\n",
    "        comment=\"Descriçao do desfecho. Texto livre. Exemplo: Alta médica melhorado\"\n",
    "    )\n",
    "\n",
    "    # Relações\n",
    "    paciente: Mapped[\"Paciente\"] = backref(\"desfechos\")\n",
    "\n",
    "    __table_args__: tuple[pkc,] = (pkc(\"ID_Paciente\", \"ID_Atendimento\"),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe80313-f7f6-4dce-9e55-6eb920fa9bb1",
   "metadata": {},
   "source": [
    "## População dos bancos de dados\n",
    "\n",
    "Abaixo descrevemos a lógica para população dos bancos de dados. Os datasets que descrevem a cada tabela de cada banco de dados estão localizados em uma pasta `dataset` colocada no mesmo diretório que este notebook.\n",
    "\n",
    "```bash\n",
    "~/Public/USP/Ciência da Computação/Semestre 6/Mineração de dados/01-Introdução-Preparação de dados main*\n",
    "❄️impure ❯ exa --tree\n",
    ".\n",
    "├── datasets\n",
    "│   ├── BPSP\n",
    "│   │   ├── BPSP_Desfechos.csv\n",
    "│   │   ├── BPSP_ExamLabs.csv\n",
    "│   │   └── BPSP_Pacientes.csv\n",
    "│   ├── Einstein\n",
    "│   │   ├── Einstein_ExamLabs.csv\n",
    "│   │   └── Einstein_Pacientes.csv\n",
    "│   ├── GrupoFleury\n",
    "│   │   ├── GrupoFleury_ExamLabs.csv\n",
    "│   │   └── GrupoFleury_Pacientes.csv\n",
    "│   ├── HC\n",
    "│   │   ├── HC_ExamLabs.csv\n",
    "│   │   └── HC_Pacientes.csv\n",
    "│   └── HSL\n",
    "│       ├── HSL_Desfechos.csv\n",
    "│       ├── HSL_ExamLabs.csv\n",
    "│       └── HSL_Pacientes.csv\n",
    "└── 'Geração de Databases com SQLalchemy e PostgreSQL.ipynb'\n",
    "```\n",
    "Como se vê, os datasets encontram-se nomeados de maneira padronizada, e os nomes das colunas de suas tabelas correspondem aos nomes dados aos atributos das classes que aqui descrevem as tabelas contidas nos BDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbd70006-1e3c-4501-b06c-f41d21ef60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = \"/datasets\"\n",
    "hospitals = [\"BPSP\", \"Einstein\", \"GrupoFleury\", \"HC\", \"HSL\"]\n",
    "tables_dict = {\"Pacientes\": Paciente, \"ExamLabs\": ExamLab, \"Desfechos\": Desfecho}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed38079-7d67-40d9-84e4-7e7cc8a73f84",
   "metadata": {},
   "source": [
    "### Criação do Banco de Dados\n",
    "\n",
    "As duas células seguintes executam a criação do banco de dados e dos _schemas_ para cada hospital, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c26d42ef-c577-4b21-b82a-669af0e2df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-12 18:07:03,402 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-12 18:07:03,403 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-12 18:07:03,403 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-12 18:07:03,403 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-12 18:07:03,404 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-12 18:07:03,404 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-12 18:07:03,405 INFO sqlalchemy.engine.Engine BEGIN (implicit; DBAPI should not BEGIN due to autocommit mode)\n",
      "2025-09-12 18:07:03,405 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS BPSP\n",
      "2025-09-12 18:07:03,405 INFO sqlalchemy.engine.Engine [generated in 0.00048s] {}\n",
      "2025-09-12 18:07:03,405 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS Einstein\n",
      "2025-09-12 18:07:03,405 INFO sqlalchemy.engine.Engine [generated in 0.00017s] {}\n",
      "2025-09-12 18:07:03,406 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS GrupoFleury\n",
      "2025-09-12 18:07:03,406 INFO sqlalchemy.engine.Engine [generated in 0.00017s] {}\n",
      "2025-09-12 18:07:03,406 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS HC\n",
      "2025-09-12 18:07:03,406 INFO sqlalchemy.engine.Engine [generated in 0.00015s] {}\n",
      "2025-09-12 18:07:03,407 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS HSL\n",
      "2025-09-12 18:07:03,407 INFO sqlalchemy.engine.Engine [generated in 0.00016s] {}\n",
      "2025-09-12 18:07:03,407 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS D2\n",
      "2025-09-12 18:07:03,407 INFO sqlalchemy.engine.Engine [generated in 0.00023s] {}\n",
      "2025-09-12 18:07:03,408 INFO sqlalchemy.engine.Engine ROLLBACK using DBAPI connection.rollback(); set skip_autocommit_rollback to prevent fully\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DATABASE_URI, echo=True)\n",
    "\n",
    "with engine.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    for hospital in hospitals + [\"D2\"]:\n",
    "        conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {hospital}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4619216d-9ad2-49e8-b72b-07b69460a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating table Pacientes from BPSP schema: 1it [00:01,  1.55s/it]\n",
      "Populating table ExamLabs from BPSP schema: 4it [06:46, 101.63s/it]\n",
      "Populating table Desfechos from BPSP schema: 1it [00:09,  9.75s/it]\n",
      "Populating table Pacientes from Einstein schema: 1it [00:03,  3.12s/it]\n",
      "Populating table ExamLabs from Einstein schema: 2it [05:00, 150.29s/it]\n",
      "Populating table Pacientes from GrupoFleury schema: 1it [00:22, 22.51s/it]\n",
      "Populating table ExamLabs from GrupoFleury schema: 10it [25:30, 153.10s/it]\n",
      "Populating table Pacientes from HC schema: 1it [00:00,  4.45it/s]\n",
      "Populating table ExamLabs from HC schema: 2it [02:10, 65.44s/it] \n",
      "Populating table Pacientes from HSL schema: 1it [00:00,  1.71it/s]\n",
      "Populating table ExamLabs from HSL schema: 1it [01:02, 62.77s/it]\n",
      "Populating table Desfechos from HSL schema: 1it [00:02,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "def batch_insert(session: Session, hospital: str, table_name: str, table_class) -> None:\n",
    "    chunks = pd.read_csv(\n",
    "        f\"{datasets_folder}/{hospital}/{hospital}_{table_name}.csv\",\n",
    "        delimiter=\"|\",\n",
    "        encoding=\"utf-8\",\n",
    "        low_memory=False,\n",
    "        chunksize=BATCH_SIZE,\n",
    "        dtype = {'CD_Unidade': str}\n",
    "    )\n",
    "    pbar = tqdm(\n",
    "        chunks, desc=f\"Populating table {table_name} from {hospital} schema\"\n",
    "    )\n",
    "    \n",
    "    if table_name == \"Pacientes\":\n",
    "        for df in pbar:\n",
    "            df.rename(columns=normalize_column_name, inplace=True)\n",
    "            # AA_Nascimento verification. Condition 1: Value is 'AAAA' or 'YYYY'\n",
    "            is_placeholder = df['AA_Nascimento'].isin(['AAAA', 'YYYY'])\n",
    "    \n",
    "            # Condition 2: Value is a 4-digit string\n",
    "            # Ensure it's a string before using .str accessor\n",
    "            is_4_digit_year = (df['AA_Nascimento'].astype(str).str.isdigit()) & \\\n",
    "                              (df['AA_Nascimento'].astype(str).str.len() == 4)\n",
    "    \n",
    "            # Combine conditions: A row is valid if it meets Condition 1 OR Condition 2\n",
    "            valid_mask = is_placeholder | is_4_digit_year\n",
    "    \n",
    "            df.loc[~valid_mask, 'AA_Nascimento'] = None\n",
    "            df['CD_Pais'] = df['CD_Pais'].replace('XX', None)\n",
    "            df['CD_UF'] = df['CD_UF'].replace('UU', None)\n",
    "            df['CD_Municipio'] = df['CD_Municipio'].replace('MMMM', None)\n",
    "            df['CD_CEPReduzido'] = df['CD_CEPReduzido'].replace('CCCC', None)\n",
    "            session.execute(insert(table_class), df.to_dict('records'))\n",
    "    else:\n",
    "        result = session.execute(text('SELECT \"ID_Paciente\" FROM \"Pacientes\"'))\n",
    "        valid_patient_ids = {row[0] for row in result}\n",
    "        if table_name == \"ExamLabs\":\n",
    "            for df in pbar:\n",
    "                df.rename(columns=normalize_column_name, inplace=True)\n",
    "                df = df[df['ID_Paciente'].isin(valid_patient_ids)].copy()\n",
    "                df['DT_Coleta'] = parse_date(df['DT_Coleta'])\n",
    "                df = df.astype(object).where(pd.notna(df), None)\n",
    "                session.execute(insert(table_class), df.to_dict('records'))\n",
    "        else:\n",
    "            for df in pbar:\n",
    "                df.rename(columns=normalize_column_name, inplace=True)\n",
    "                df = df[df['ID_Paciente'].isin(valid_patient_ids)].copy()\n",
    "                df['DT_Atendimento'] = parse_date(df['DT_Atendimento'])\n",
    "                df['DT_Desfecho'] = parse_date(df['DT_Desfecho'])\n",
    "                df = df.astype(object).where(pd.notna(df), None)\n",
    "                session.execute(insert(table_class), df.to_dict('records'))\n",
    "\n",
    "\n",
    "for hospital in hospitals:\n",
    "    engine = create_engine(\n",
    "        DATABASE_URI,\n",
    "        connect_args={'options': f'-c search_path={hospital}'},\n",
    "    )\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    \n",
    "    with Session() as session:\n",
    "        Base.metadata.create_all(engine)\n",
    "        session.commit()\n",
    "\n",
    "        for table_name, table_class in tables_dict.items():\n",
    "            try:\n",
    "                batch_insert(session, hospital, table_name, table_class)\n",
    "                session.commit()\n",
    "            except FileNotFoundError:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b687256-ced7-4b53-bc44-95f88ef9c000",
   "metadata": {},
   "source": [
    "O resultado esperado desta execução é a criação dos seguintes BDs estruturados tal qual exibe os seguinte diagrama gerado usando a ferramenta DBeaver:\n",
    "\n",
    "![Estrutura do BD, onde Pacientes figura como uma tabela associada a ExamLabs e Despachos](imgs/db_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04e2c7-e1c9-4e01-b55b-5a47f12535fe",
   "metadata": {},
   "source": [
    "# Criação de novo banco de dados para a análise de dados\n",
    "\n",
    "Em seguida, criamos um novo BD para conter dados agregados a todos os demais BDs. Isto, conforme os critérios de seleção vistos na tabela AnalisesCovid, descrita a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39390baa-1077-4703-adb5-59d4dbdcb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnaliseCovid(PacienteBase):\n",
    "    \"\"\"\n",
    "    Tabela de análises Covid-19 FAPESP\n",
    "\n",
    "    Complementa a tabela Paciente com dados relevantes sobre atendimentos,\n",
    "    exames e desfechos extraídos das tabelas ExamLabs e Desfechos para análise\n",
    "    epidemiológica de casos associados ao COVID-19\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"AnalisesCovid\"\n",
    "    id: Mapped[int] = column(autoincrement=True, primary_key=True)\n",
    "\n",
    "    # Aggregated data\n",
    "    ID_Paciente: Mapped[str] = column(\n",
    "        comment=\"Identificação única do paciente (32 caracteres alfanuméricos)\"\n",
    "    )\n",
    "    ID_Atendimento: Mapped[str | None] = column(\n",
    "        comment=\"Identificação única do atendimento (32 caracteres alfanuméricos)\"\n",
    "    )\n",
    "    DT_Coleta: Mapped[date | None] = column(\n",
    "        comment=\"Data em que o material foi coletado para exame\"\n",
    "    )\n",
    "    DT_Atendimento: Mapped[date | None] = column(\n",
    "        comment=\"Data de realização do atendimento\"\n",
    "    )\n",
    "    DT_Desfecho: Mapped[date | None] = column(\n",
    "        comment=\"Data do desfecho do paciente (alta, óbito, etc.)\"\n",
    "    )\n",
    "    DE_Desfecho: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do desfecho do paciente (ex: 'Alta médica melhorado', 'Óbito')\"\n",
    "    )\n",
    "    DE_Exame: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do exame realizado (ex: 'Teste COVID-19', 'Hemograma')\"\n",
    "    )\n",
    "    DE_Resultado: Mapped[str | None]\n",
    "\n",
    "    # Added metadata\n",
    "    DE_Classe: Mapped[str | None] = column(\n",
    "        Enum('P', 'N', name='classe_enum'),\n",
    "        comment=\"Resultado do exame COVID-19 simplificado (P - Positivo, N - Negativo, None - Outro/Indeterminado)\"\n",
    "    )\n",
    "    DE_Hospital: Mapped[str] = column(\n",
    "        comment=\"Identificação do hospital de origem dos dados (BPSP, Einstein, GrupoFleury, HC, HSL)\"\n",
    "    )\n",
    "\n",
    "class PacienteD2(Paciente):\n",
    "    DE_Hospital: Mapped [str]\n",
    "\n",
    "class ExamLabD2(ExamLab):\n",
    "    DE_Hospital: Mapped [str]\n",
    "\n",
    "class DesfechoD2(Desfecho):\n",
    "    DE_Hospital: Mapped [str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6f615-68ca-4a12-b600-dca4428eed55",
   "metadata": {},
   "source": [
    "## População do BD D2 com dados dos demais BDs\n",
    "\n",
    "Em seguida acessamos aos demais BDs um a um e criamos registros correspondentes no DB D2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a6be02b-2dde-4dae-923f-fe247a8219ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-12 19:53:42,445 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-12 19:53:42,445 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-12 19:53:42,447 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-12 19:53:42,447 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-12 19:53:42,448 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-12 19:53:42,449 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-12 19:53:42,449 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-12 19:53:42,451 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,452 INFO sqlalchemy.engine.Engine [generated in 0.00052s] {'table_name': 'AnalisesCovid', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,457 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,458 INFO sqlalchemy.engine.Engine [cached since 0.006309s ago] {'table_name': 'Pacientes', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,459 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,459 INFO sqlalchemy.engine.Engine [cached since 0.008172s ago] {'table_name': 'ExamLabs', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,460 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,461 INFO sqlalchemy.engine.Engine [cached since 0.00953s ago] {'table_name': 'Desfechos', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,462 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,463 INFO sqlalchemy.engine.Engine [generated in 0.00037s] {'typname_1': 'sexo_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,465 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,465 INFO sqlalchemy.engine.Engine [cached since 0.002974s ago] {'typname_1': 'estado_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,467 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-12 19:53:42,467 INFO sqlalchemy.engine.Engine [cached since 0.004978s ago] {'typname_1': 'classe_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-12 19:53:42,468 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "# Populate a new database D2 with its tables\n",
    "engine = create_engine(\n",
    "    DATABASE_URI,\n",
    "    connect_args={'options': f'-c search_path=D2'},\n",
    "    echo = True\n",
    ")\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "with Session() as session:\n",
    "    tables = [\n",
    "        AnaliseCovid.__table__,\n",
    "        PacienteD2.__table__,\n",
    "        ExamLabD2.__table__,\n",
    "        DesfechoD2.__table__,\n",
    "    ]\n",
    "    Base.metadata.create_all(engine, tables=tables)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d74be-c382-452e-b41a-225d8ea7355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Copying BPSP.Pacientes data ---\n",
      "Error copying BPSP.Pacientes: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"Pacientes_pkey\"\n",
      "DETAIL:  Key (\"ID_Paciente\")=(62AEF279AE23B7BD) already exists.\n",
      "\n",
      "[SQL: \n",
      "                INSERT INTO D2.\"Pacientes\" (\"ID_Paciente\", \"IC_Sexo\", \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\", \"CD_Municipio\", \"CD_CEPReduzido\", \"DE_Hospital\")\n",
      "                SELECT \"ID_Paciente\", \"IC_Sexo\"::text::d2.sexo_enum, \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\"::text::d2.estado_enum, \"CD_Municipio\", \"CD_CEPReduzido\", 'BPSP' as \"DE_Hospital\" \n",
      "                FROM BPSP.\"Pacientes\"\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "--- Copying Einstein.Pacientes data ---\n",
      "Error copying Einstein.Pacientes: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"Pacientes_pkey\"\n",
      "DETAIL:  Key (\"ID_Paciente\")=(13d016bccfdd1b92039607f025f9dd87a03c3bcb) already exists.\n",
      "\n",
      "[SQL: \n",
      "                INSERT INTO D2.\"Pacientes\" (\"ID_Paciente\", \"IC_Sexo\", \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\", \"CD_Municipio\", \"CD_CEPReduzido\", \"DE_Hospital\")\n",
      "                SELECT \"ID_Paciente\", \"IC_Sexo\"::text::d2.sexo_enum, \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\"::text::d2.estado_enum, \"CD_Municipio\", \"CD_CEPReduzido\", 'Einstein' as \"DE_Hospital\" \n",
      "                FROM Einstein.\"Pacientes\"\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "--- Copying GrupoFleury.Pacientes data ---\n",
      "Error copying GrupoFleury.Pacientes: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"Pacientes_pkey\"\n",
      "DETAIL:  Key (\"ID_Paciente\")=(1AD07C7A1E4D80B608DD7A650766CCF0) already exists.\n",
      "\n",
      "[SQL: \n",
      "                INSERT INTO D2.\"Pacientes\" (\"ID_Paciente\", \"IC_Sexo\", \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\", \"CD_Municipio\", \"CD_CEPReduzido\", \"DE_Hospital\")\n",
      "                SELECT \"ID_Paciente\", \"IC_Sexo\"::text::d2.sexo_enum, \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\"::text::d2.estado_enum, \"CD_Municipio\", \"CD_CEPReduzido\", 'GrupoFleury' as \"DE_Hospital\" \n",
      "                FROM GrupoFleury.\"Pacientes\"\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "--- Copying HC.Pacientes data ---\n",
      "Error copying HC.Pacientes: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"Pacientes_pkey\"\n",
      "DETAIL:  Key (\"ID_Paciente\")=(9698838a8fa8a01ffd5ed5c71e8e17a3) already exists.\n",
      "\n",
      "[SQL: \n",
      "                INSERT INTO D2.\"Pacientes\" (\"ID_Paciente\", \"IC_Sexo\", \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\", \"CD_Municipio\", \"CD_CEPReduzido\", \"DE_Hospital\")\n",
      "                SELECT \"ID_Paciente\", \"IC_Sexo\"::text::d2.sexo_enum, \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\"::text::d2.estado_enum, \"CD_Municipio\", \"CD_CEPReduzido\", 'HC' as \"DE_Hospital\" \n",
      "                FROM HC.\"Pacientes\"\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "--- Copying HSL.Pacientes data ---\n",
      "Error copying HSL.Pacientes: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"Pacientes_pkey\"\n",
      "DETAIL:  Key (\"ID_Paciente\")=(3487791F44C34B421C932DC8616A8437) already exists.\n",
      "\n",
      "[SQL: \n",
      "                INSERT INTO D2.\"Pacientes\" (\"ID_Paciente\", \"IC_Sexo\", \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\", \"CD_Municipio\", \"CD_CEPReduzido\", \"DE_Hospital\")\n",
      "                SELECT \"ID_Paciente\", \"IC_Sexo\"::text::d2.sexo_enum, \"AA_Nascimento\", \"CD_Pais\", \"CD_UF\"::text::d2.estado_enum, \"CD_Municipio\", \"CD_CEPReduzido\", 'HSL' as \"DE_Hospital\" \n",
      "                FROM HSL.\"Pacientes\"\n",
      "            ]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "--- Copying BPSP.ExamLabs data ---\n",
      "Copied BPSP.ExamLabs to D2.ExamLabs\n",
      "--- Copying Einstein.ExamLabs data ---\n",
      "Copied Einstein.ExamLabs to D2.ExamLabs\n",
      "--- Copying GrupoFleury.ExamLabs data ---\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DATABASE_URI)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n",
    "\n",
    "    for table_name, table_class in tables_dict.items():\n",
    "        for hospital in hospitals:\n",
    "            print(f\"--- Copying {hospital}.{table_name} data ---\")    \n",
    "            columns = [\n",
    "                col for col in table_class.__table__.columns if col.name != \"id\" \n",
    "            ]\n",
    "            insert_columns = \", \".join([f'\"{col.name}\"' for col in columns])\n",
    "\n",
    "            # Apply the explicit DOUBLE CAST for Enum types\n",
    "            select_columns = \", \".join([\n",
    "                f'\"{col.name}\"::text::d2.{col.type.name}'\n",
    "                if isinstance(col.type, Enum)\n",
    "                else f'\"{col.name}\"'\n",
    "                for col in columns\n",
    "                if col.name != \"DE_Hospital\"\n",
    "            ])\n",
    "            \n",
    "            copy_sql = f\"\"\"\n",
    "                INSERT INTO D2.\"{table_name}\" ({insert_columns})\n",
    "                SELECT {select_columns}, '{hospital}' as \"DE_Hospital\" \n",
    "                FROM {hospital}.\"{table_name}\"\n",
    "            \"\"\"\n",
    "            try:\n",
    "                conn.execute(text(copy_sql))\n",
    "                print(f\"Copied {hospital}.{table_name} to D2.{table_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {hospital}.{table_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3565d-f044-4482-9ece-8b8a8a94cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    DATABASE_URI,\n",
    "    connect_args={'options': f'-c search_path=D2'},\n",
    ")\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "with Session() as session:\n",
    "    query = (\n",
    "        session.query(\n",
    "            PacienteD2,          # Select the entire PacienteD2 object\n",
    "            ExamLabD2.DE_Exame,\n",
    "            ExamLabD2.DE_Resultado,\n",
    "            ExamLabD2.DT_Coleta,\n",
    "            ExamLabD2.ID_Atendimento,\n",
    "            DesfechoD2.DE_Desfecho,\n",
    "            DesfechoD2.DT_Desfecho,\n",
    "            DesfechoD2.DT_Atendimento\n",
    "        )\n",
    "        .select_from(PacienteD2)\n",
    "        .join(ExamLabD2, PacienteD2.ID_Paciente == ExamLabD2.ID_Paciente)\n",
    "        .join(\n",
    "            DesfechoD2,\n",
    "            (PacienteD2.ID_Paciente == DesfechoD2.ID_Paciente)\n",
    "            & (ExamLabD2.ID_Atendimento == DesfechoD2.ID_Atendimento),\n",
    "        )\n",
    "        .filter(\n",
    "            ExamLabD2.DE_Exame.ilike(\"%covid%\")\n",
    "            | ExamLabD2.DE_Exame.ilike(\"%corona%\")\n",
    "            | ExamLabD2.DE_Exame.ilike(\"%sars%\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "    for chunk in tqdm(query.yield_per(BATCH_SIZE), desc=\"Processando registros\"):\n",
    "        temp_exam = ExamLab(\n",
    "            DE_Exame=chunk.DE_Exame, DE_Resultado=chunk.DE_Resultado\n",
    "        )\n",
    "\n",
    "        match temp_exam.DE_resultNum:\n",
    "            case -1000:\n",
    "                classe = \"P\"\n",
    "            case -1111:\n",
    "                classe = \"N\"\n",
    "            case _:\n",
    "                classe = None\n",
    "\n",
    "        records.append (\n",
    "            {\n",
    "                \"ID_Paciente\": chunk.PacienteD2.ID_Paciente,\n",
    "                \"ID_Atendimento\": chunk.ID_Atendimento,\n",
    "                \"IC_Sexo\": chunk.PacienteD2.IC_Sexo,\n",
    "                \"AA_Nascimento\": chunk.PacienteD2.AA_Nascimento,\n",
    "                \"CD_UF\": chunk.PacienteD2.CD_UF,\n",
    "                \"CD_Pais\": chunk.PacienteD2.CD_Pais,\n",
    "                \"CD_Municipio\": chunk.PacienteD2.CD_Municipio,\n",
    "                \"CD_CEPReduzido\": chunk.PacienteD2.CD_CEPReduzido,\n",
    "                \"DT_Atendimento\": chunk.DT_Atendimento,\n",
    "                \"DT_Coleta\": chunk.DT_Coleta,\n",
    "                \"DE_Exame\": chunk.DE_Exame,\n",
    "                \"DT_Desfecho\": chunk.DT_Desfecho,\n",
    "                \"DE_Desfecho\": chunk.DE_Desfecho,\n",
    "                \"DE_Resultado\": chunk.DE_Resultado,\n",
    "                \"DE_Classe\": classe,\n",
    "                \"DE_Hospital\": chunk.PacienteD2.DE_Hospital,\n",
    "            }\n",
    "        )\n",
    "    if records:\n",
    "        session.execute(insert(AnaliseCovid), records)\n",
    "        session.commit()\n",
    "\n",
    "df = pd.read_sql_table(\"AnalisesCovid\", engine)\n",
    "print(\"\\n--- Verificando tabela resultante ---\")\n",
    "print(df.head())\n",
    "print(f\"\\nTotal de entradas em AnalisesCovid: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c2480-c9bd-405f-a0be-ed21b9cad093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
