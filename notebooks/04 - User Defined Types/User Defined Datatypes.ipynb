{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb25ad57-ce0a-4d7a-a867-a6ae947f0be8",
   "metadata": {},
   "source": [
    "## Autores\n",
    "\n",
    "| Nome | nUSP |\n",
    "| :--- | :--- |\n",
    "| Guilherme de Abreu Barreto | 12543033 |\n",
    "| Lucas Eduardo Gulka Pulcinelli | 12547336 |\n",
    "| Vinicio Yusuke Hayashibara | 13642797 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804ab7b6-3450-43c2-afab-c3b6ace19568",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DATABASE = \"postgres\"\n",
    "CENSO_DATABASE = \"censo2022\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"postgres\"\n",
    "HOST = \"localhost\"\n",
    "PORT = 5432\n",
    "URI = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36e35410-453c-4bf3-9434-f6eaf4e2ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from math import sqrt\n",
    "from sqlalchemy import (\n",
    "    BigInteger,\n",
    "    Float,\n",
    "    Integer,\n",
    "    UniqueConstraint as unique,\n",
    "    PrimaryKeyConstraint as pkc,\n",
    "    ForeignKeyConstraint as fkc,\n",
    "    ForeignKey as fk,\n",
    "    JSON,\n",
    "    cast,\n",
    "    create_engine,\n",
    "    insert,\n",
    "    text,\n",
    "    func,\n",
    ")\n",
    "from sqlalchemy.orm import (\n",
    "    Mapped,\n",
    "    Session,\n",
    "    composite,\n",
    "    declarative_base,\n",
    "    relationship,\n",
    "    sessionmaker,\n",
    "    mapped_column as column,\n",
    ")\n",
    "from sqlalchemy.dialects.postgresql import ENUM\n",
    "from sqlalchemy.ext.hybrid import hybrid_method, hybrid_property\n",
    "from typing import Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9363de9-0448-4cef-87cc-84107c3cc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backref(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(back_populates=back_populates)\n",
    "\n",
    "\n",
    "def childOf(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(\n",
    "        back_populates=back_populates,\n",
    "        cascade=\"all, delete-orphan\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f60461-1951-4e40-a91b-a0665447ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Households:\n",
    "    def __init__(self, urban: int, rural: int) -> None:\n",
    "        self.urban = urban\n",
    "        self.rural = rural\n",
    "\n",
    "    def __composite_values__(self) -> tuple[int, ...]:\n",
    "        return (self.urban, self.rural)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Households) and \\\n",
    "               other.urban == self.urban and \\\n",
    "               other.rural == self.rural\n",
    "        \n",
    "    @hybrid_property\n",
    "    def total(self):\n",
    "        \"\"\"Python-side property for total households.\"\"\"\n",
    "        return self.urban + self.rural\n",
    "\n",
    "    @total.expression\n",
    "    def total(cls):\n",
    "        \"\"\"SQL-side expression for querying total households.\"\"\"\n",
    "        return cls.urban + cls.rural\n",
    "\n",
    "class Coordinate:\n",
    "    \"\"\"\n",
    "    A geographic coordinate point with longitude (lon) and latitude (lat) components.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, longitude: float, latitude: float) -> None:\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "\n",
    "    @property\n",
    "    def longitude(self) -> float:\n",
    "        return self._longitude\n",
    "\n",
    "    @longitude.setter\n",
    "    def longitude(self, value: float) -> None:\n",
    "        if not (-180 <= value <= 180):\n",
    "            raise ValueError(f\"Longitude must be between -180 and 180 degrees, got {value}\")\n",
    "        self._longitude = value\n",
    "\n",
    "    @property\n",
    "    def latitude(self) -> float:\n",
    "        return self._latitude\n",
    "\n",
    "    @latitude.setter\n",
    "    def latitude(self, value: float) -> None:\n",
    "        if not (-90 <= value <= 90):\n",
    "            raise ValueError(f\"Latitude must be between -90 and 90 degrees, got {value}\")\n",
    "        self._latitude = value\n",
    "\n",
    "    def __composite_values__(self) -> tuple[float, ...]:\n",
    "        return (self.longitude, self.latitude)\n",
    "\n",
    "    def __eq__(self, other: \"Coordinate\") -> bool:\n",
    "        return isinstance(other, Coordinate) and \\\n",
    "               other.longitude == self.longitude and \\\n",
    "               other.latitude == self.latitude\n",
    "        \n",
    "    def __ne__ (self, other: \"Coordinate\") -> bool:\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    @hybrid_method\n",
    "    def distance(\n",
    "        self,\n",
    "        other: \"Coordinate\",\n",
    "        metric: str = 'euclidean'\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate distance to another coordinate.\n",
    "        \n",
    "        Args:\n",
    "            other: Coordinate instance\n",
    "            metric: 'euclidean' or 'manhattan'\n",
    "        \n",
    "        Returns:\n",
    "            Distance between coordinates\n",
    "        \"\"\"\n",
    "        x = self.longitude - other.longitude\n",
    "        y = self.latitude - other.latitude\n",
    "        match metric:\n",
    "            case 'euclidean':\n",
    "                return sqrt(x**2 + y**2)\n",
    "            case 'manhattan':\n",
    "                return abs(x) + abs(y)\n",
    "            case _:\n",
    "                raise ValueError(\"Metric must be 'euclidean' or 'manhattan'\")\n",
    "\n",
    "    @distance.expression\n",
    "    def distance(\n",
    "        cls,\n",
    "        other_lon: float,\n",
    "        other_lat: float,\n",
    "        metric: str = 'euclidean'\n",
    "    ):\n",
    "        match metric:\n",
    "            case 'euclidean':\n",
    "                return func.sqrt(\n",
    "                    (cls.x - other_x) * (cls.x - other_x) +\n",
    "                    (cls.y - other_y) * (cls.y - other_y)\n",
    "                )\n",
    "            case 'manhattan':\n",
    "                return func.abs(cls.x - other_x) + func.abs(cls.y - other_y)\n",
    "            case _:\n",
    "                raise ValueError(\"Metric must be 'euclidean' or 'manhattan'\")\n",
    "\n",
    "\n",
    "class Biomes:\n",
    "    default: dict[str, float] = {\n",
    "        biome: 0.0 for biome in [\n",
    "            'amazon_rainforest',\n",
    "            'atlantic_forest',\n",
    "            'caatinga',\n",
    "            'cerrado',\n",
    "            'pantanal',\n",
    "            'pampas'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.distribution = kargs\n",
    "\n",
    "    def __composite_values__(self) -> tuple[float, ...]:\n",
    "        return tuple(getattr(self, biome) for biome in self.default.keys())\n",
    "\n",
    "    @property\n",
    "    def distribution(self) -> dict[str, float]:\n",
    "        return {biome: getattr(self, biome) for biome in self.default.keys()}\n",
    "\n",
    "\n",
    "    @distribution.setter\n",
    "    def distribution(self, values: dict[str, float]) -> None:\n",
    "        merged_values = {**self.default, **values}\n",
    "\n",
    "        # Validation\n",
    "        invalid_keys = set(merged_values.keys()) - set(self.default.keys())\n",
    "        if invalid_keys:\n",
    "            raise ValueError(f\"Invalid biome types: {invalid_keys}. Valid types are: {list(self.default.keys())}\")\n",
    "        total = sum(merged_values.values())\n",
    "        if 99.9 <= total <= 100.1:\n",
    "            raise ValueError(f\"Invalid biome distribution, totalling {total:.1f}%\")\n",
    "        self._distribution = merged_values\n",
    "\n",
    "        for biome_type, value in merged_values.items():\n",
    "            setattr(self, biome_type, value)\n",
    "\n",
    "    @property\n",
    "    def total(self) -> float:\n",
    "        return sum(getattr(self, biome) for biome in self.default.keys)\n",
    "\n",
    "    @classmethod\n",
    "    def toList(cls) -> list[str]:\n",
    "        return list(cls.default.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a55a5be-368e-4285-b77b-da320d68b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_enum = ENUM(*[\n",
    "    \"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \n",
    "    \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \n",
    "    \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"\n",
    "], name=\"state_enum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "198f174f-0553-4092-8f21-9d1f041c0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Region(Base):\n",
    "    __tablename__: str = \"regions\"\n",
    "\n",
    "    # Attributes\n",
    "    id: Mapped[int] = column(autoincrement=True, primary_key=True)\n",
    "    name: Mapped[str] = column(unique=True)\n",
    "\n",
    "    # Relationships\n",
    "    states: Mapped[list[\"State\"]] = childOf('region')\n",
    "\n",
    "\n",
    "class State(Base):\n",
    "    __tablename__: str = \"states\"\n",
    "\n",
    "    # Attributes\n",
    "    id: Mapped[int] = column(autoincrement=True)\n",
    "    name: Mapped[str] = column(unique=True)\n",
    "    uf: Mapped[str] = column(state_enum, unique=True)\n",
    "    location: Mapped[Coordinate] = composite(\n",
    "        column(\"longitude\", Float),\n",
    "        column(\"latitude\", Float)\n",
    "    )\n",
    "    area: Mapped[float]\n",
    "    biome_distribution: Mapped[Biomes] = composite(\n",
    "        *[column(biome, Float) for biome in Biomes.toList()]\n",
    "    )\n",
    "\n",
    "    # Foreign keys\n",
    "    region_id: Mapped[int] = column(fk(\"regions.id\"))\n",
    "    capital_id: Mapped[int | None]\n",
    "\n",
    "    # Relationships\n",
    "    region: Mapped[\"Region\"] = backref(\"states\")\n",
    "    capital: Mapped[Optional[\"City\"]] = relationship(\n",
    "        foreign_keys=\"State.capital_id\"\n",
    "    )\n",
    "    cities: Mapped[list[\"City\"]] = childOf(\"state\")\n",
    "\n",
    "    __table_args__: tuple[pkc, fkc, unique,] = (\n",
    "        pkc(\"region_id\", \"id\"),\n",
    "        fkc(\n",
    "            [\"capital_id\", \"id\"],\n",
    "            [\"cities.id\", \"cities.state_id\"],\n",
    "            name='fk_capital_cmposite'\n",
    "        ),\n",
    "        unique('longitude', 'latitude', name='uq_state_location'),\n",
    "    )\n",
    "\n",
    "\n",
    "class City(Base):\n",
    "    __tablename__: str = \"cities\"\n",
    "\n",
    "    # Attributes\n",
    "    id: Mapped[int] = column(autoincrement=True)\n",
    "    name: Mapped[str]\n",
    "    location: Mapped[Coordinate] = composite(\n",
    "        column(\"longitude\", Float),\n",
    "        column(\"latitude\", Float)\n",
    "    )\n",
    "    ddd: Mapped[int]\n",
    "    households: Mapped[Households] = composite(\n",
    "        column(\"urban\", Integer),\n",
    "        column(\"rural\", Integer)\n",
    "    )\n",
    "    population_race: Mapped[dict] = column(JSON)\n",
    "    population_education: Mapped[dict] = column(JSON)\n",
    "    \n",
    "\n",
    "    # Foreign keys\n",
    "    timezone_name: Mapped[str] = column(fk(\"timezones.name\"))\n",
    "    region_id: Mapped[int]\n",
    "    state_id: Mapped[int]\n",
    "\n",
    "    # Relationships\n",
    "    timezone: Mapped[\"UTC_Timezone\"] = backref(\"cities\")\n",
    "    state: Mapped[\"State\"] = backref(\"cities\")\n",
    "\n",
    "    @hybrid_property\n",
    "    def ibge_code(self):\n",
    "        \"\"\"Python-side property to get the IBGE code.\"\"\"\n",
    "        return int(f\"{self.state.region_id}{self.state_id}{self.id}\")\n",
    "\n",
    "    @ibge_code.expression\n",
    "    def ibge_code(cls):\n",
    "        \"\"\"SQL-side expression for querying.\"\"\"\n",
    "        return cast(\n",
    "            func.concat(\n",
    "                # Join to State to get the region ID\n",
    "                cast(cls.state.region_id, String),\n",
    "                cast(cls.state_id, String),\n",
    "                cast(cls.id, String)\n",
    "            ),\n",
    "            BigInteger\n",
    "        )\n",
    "\n",
    "    __table_args__: tuple[pkc, fkc, unique, ] = (\n",
    "        pkc(\"state_id\", \"id\"),\n",
    "        fkc(\n",
    "            ['region_id', 'state_id'],\n",
    "            ['states.region_id', 'states.id'],\n",
    "            name='fk_region_composite'\n",
    "        ),\n",
    "        unique(\"longitude\", \"latitude\", name=\"uq_city_location\")\n",
    "    )\n",
    "\n",
    "\n",
    "class Timezone(Base):\n",
    "    __tablename__: str = \"timezones\"\n",
    "\n",
    "    # Attributes\n",
    "    name: Mapped[str] = column(primary_key=True)\n",
    "    utc_offset: Mapped[int]\n",
    "\n",
    "    # Relationships\n",
    "    cities: Mapped[list[\"City\"]] = backref('timezone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7d8296-2d1b-4358-92f0-b1a304f6875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-19 16:38:17,678 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-19 16:38:17,679 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-19 16:38:17,681 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-19 16:38:17,682 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-19 16:38:17,684 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-19 16:38:17,685 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-19 16:38:17,687 INFO sqlalchemy.engine.Engine BEGIN (implicit; DBAPI should not BEGIN due to autocommit mode)\n",
      "2025-09-19 16:38:17,688 INFO sqlalchemy.engine.Engine CREATE DATABASE censo2022\n",
      "2025-09-19 16:38:17,689 INFO sqlalchemy.engine.Engine [generated in 0.00187s] {}\n",
      "2025-09-19 16:38:17,750 INFO sqlalchemy.engine.Engine ROLLBACK using DBAPI connection.rollback(), DBAPI should ignore due to autocommit mode\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(URI + DEFAULT_DATABASE, echo=True)\n",
    "\n",
    "with engine.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE {CENSO_DATABASE}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07a4df84-58fa-458a-a1a3-e5707bad84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-19 16:38:25,306 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-19 16:38:25,306 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-19 16:38:25,308 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-19 16:38:25,309 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-19 16:38:25,312 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-19 16:38:25,312 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-19 16:38:25,314 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-19 16:38:25,317 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-19 16:38:25,318 INFO sqlalchemy.engine.Engine [generated in 0.00109s] {'table_name': 'regions', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-19 16:38:25,321 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-19 16:38:25,322 INFO sqlalchemy.engine.Engine [cached since 0.005049s ago] {'table_name': 'states', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-19 16:38:25,323 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-19 16:38:25,324 INFO sqlalchemy.engine.Engine [cached since 0.007468s ago] {'table_name': 'cities', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-19 16:38:25,326 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-19 16:38:25,327 INFO sqlalchemy.engine.Engine [cached since 0.01066s ago] {'table_name': 'timezones', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-19 16:38:25,331 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-19 16:38:25,333 INFO sqlalchemy.engine.Engine [generated in 0.00186s] {'typname_1': 'state_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-19 16:38:25,336 INFO sqlalchemy.engine.Engine CREATE TYPE state_enum AS ENUM ('AC', 'AL', 'AP', 'AM', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MT', 'MS', 'MG', 'PA', 'PB', 'PR', 'PE', 'PI', 'RJ', 'RN', 'RS', 'RO', 'RR', 'SC', 'SP', 'SE', 'TO')\n",
      "2025-09-19 16:38:25,337 INFO sqlalchemy.engine.Engine [no key 0.00103s] {}\n",
      "2025-09-19 16:38:25,341 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE regions (\n",
      "\tid SERIAL NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tPRIMARY KEY (id), \n",
      "\tUNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-19 16:38:25,342 INFO sqlalchemy.engine.Engine [no key 0.00095s] {}\n",
      "2025-09-19 16:38:25,359 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE states (\n",
      "\tid SERIAL NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tuf state_enum NOT NULL, \n",
      "\tlongitude FLOAT, \n",
      "\tlatitude FLOAT, \n",
      "\tarea FLOAT NOT NULL, \n",
      "\tamazon_rainforest FLOAT, \n",
      "\tatlantic_forest FLOAT, \n",
      "\tcaatinga FLOAT, \n",
      "\tcerrado FLOAT, \n",
      "\tpantanal FLOAT, \n",
      "\tpampas FLOAT, \n",
      "\tregion_id INTEGER NOT NULL, \n",
      "\tcapital_id INTEGER, \n",
      "\tPRIMARY KEY (region_id, id), \n",
      "\tCONSTRAINT uq_state_location UNIQUE (longitude, latitude), \n",
      "\tUNIQUE (name), \n",
      "\tUNIQUE (uf)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-19 16:38:25,360 INFO sqlalchemy.engine.Engine [no key 0.00124s] {}\n",
      "2025-09-19 16:38:25,385 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE cities (\n",
      "\tid SERIAL NOT NULL, \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tlongitude FLOAT, \n",
      "\tlatitude FLOAT, \n",
      "\tddd INTEGER NOT NULL, \n",
      "\turban INTEGER, \n",
      "\trural INTEGER, \n",
      "\tpopulation_race JSON NOT NULL, \n",
      "\tpopulation_education JSON NOT NULL, \n",
      "\ttimezone_name VARCHAR NOT NULL, \n",
      "\tregion_id INTEGER NOT NULL, \n",
      "\tstate_id INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (state_id, id), \n",
      "\tCONSTRAINT uq_city_location UNIQUE (longitude, latitude)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-19 16:38:25,386 INFO sqlalchemy.engine.Engine [no key 0.00086s] {}\n",
      "2025-09-19 16:38:25,401 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE timezones (\n",
      "\tname VARCHAR NOT NULL, \n",
      "\tutc_offset INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-19 16:38:25,402 INFO sqlalchemy.engine.Engine [no key 0.00089s] {}\n",
      "2025-09-19 16:38:25,411 INFO sqlalchemy.engine.Engine ALTER TABLE cities ADD FOREIGN KEY(timezone_name) REFERENCES timezones (name)\n",
      "2025-09-19 16:38:25,412 INFO sqlalchemy.engine.Engine [no key 0.00106s] {}\n",
      "2025-09-19 16:38:25,419 INFO sqlalchemy.engine.Engine ALTER TABLE states ADD CONSTRAINT fk_capital_cmposite FOREIGN KEY(capital_id, id) REFERENCES cities (id, state_id)\n",
      "2025-09-19 16:38:25,420 INFO sqlalchemy.engine.Engine [no key 0.00071s] {}\n",
      "2025-09-19 16:38:25,422 INFO sqlalchemy.engine.Engine ALTER TABLE states ADD FOREIGN KEY(region_id) REFERENCES regions (id)\n",
      "2025-09-19 16:38:25,423 INFO sqlalchemy.engine.Engine [no key 0.00069s] {}\n",
      "2025-09-19 16:38:25,426 INFO sqlalchemy.engine.Engine ALTER TABLE cities ADD CONSTRAINT fk_region_composite FOREIGN KEY(region_id, state_id) REFERENCES states (region_id, id)\n",
      "2025-09-19 16:38:25,428 INFO sqlalchemy.engine.Engine [no key 0.00218s] {}\n",
      "2025-09-19 16:38:25,434 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(URI + CENSO_DATABASE, echo=True)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf92cf-898b-4989-a0a7-438390d5c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
