{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb25ad57-ce0a-4d7a-a867-a6ae947f0be8",
   "metadata": {},
   "source": [
    "## Autores\n",
    "\n",
    "| Nome | nUSP |\n",
    "| :--- | :--- |\n",
    "| Guilherme de Abreu Barreto | 12543033 |\n",
    "| Lucas Eduardo Gulka Pulcinelli | 12547336 |\n",
    "| Vinicio Yusuke Hayashibara | 13642797 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804ab7b6-3450-43c2-afab-c3b6ace19568",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DATABASE = \"postgres\"\n",
    "CENSO_DATABASE = \"censo2022\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"postgres\"\n",
    "HOST = \"localhost\"\n",
    "PORT = 5432\n",
    "URI = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}/\"\n",
    "FILES = {\n",
    "    'states': {\n",
    "        'filepath_or_buffer': 'datasets/BREstados.csv',\n",
    "    },\n",
    "    'cities': {\n",
    "        'filepath_or_buffer': 'datasets/TabelaMunicipios.csv',\n",
    "    },\n",
    "    'households': {\n",
    "        'filepath_or_buffer': 'datasets/tabela9923.csv',\n",
    "    },\n",
    "    'race': {\n",
    "        'filepath_or_buffer': 'datasets/tabela9606.csv',\n",
    "        'sep': ';',\n",
    "        'header': None,\n",
    "        'skiprows': 1,\n",
    "    },\n",
    "    'education': {\n",
    "        'filepath_or_buffer': 'datasets/tabela10065.csv',\n",
    "        'header': None,\n",
    "        'skiprows': 1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e35410-453c-4bf3-9434-f6eaf4e2ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import re\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, fields\n",
    "from math import sqrt\n",
    "from sqlalchemy import (\n",
    "    BigInteger,\n",
    "    Float,\n",
    "    Integer,\n",
    "    Index,\n",
    "    String,\n",
    "    CheckConstraint as constraint,\n",
    "    UniqueConstraint as unique,\n",
    "    PrimaryKeyConstraint as pkc,\n",
    "    ForeignKeyConstraint as fkc,\n",
    "    ForeignKey as fk,\n",
    "    JSON,\n",
    "    cast,\n",
    "    create_engine,\n",
    "    insert,\n",
    "    text,\n",
    "    func,\n",
    "    select,\n",
    ")\n",
    "from sqlalchemy.orm import (\n",
    "    Mapped,\n",
    "    Session,\n",
    "    composite,\n",
    "    declarative_base,\n",
    "    relationship,\n",
    "    sessionmaker,\n",
    "    mapped_column as column,\n",
    "    undefer\n",
    ")\n",
    "from sqlalchemy.ext.hybrid import hybrid_method, hybrid_property\n",
    "from sqlalchemy.sql.schema import CheckConstraint\n",
    "from typing import Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6346f187-0d29-4c81-9bcd-a26920f601c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 16:00:09,046 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-20 16:00:09,047 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-20 16:00:09,049 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-20 16:00:09,050 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-20 16:00:09,052 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-20 16:00:09,053 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-20 16:00:09,056 INFO sqlalchemy.engine.Engine BEGIN (implicit; DBAPI should not BEGIN due to autocommit mode)\n",
      "2025-09-20 16:00:09,060 INFO sqlalchemy.engine.Engine \n",
      "        SELECT pg_terminate_backend(pid)\n",
      "        FROM pg_stat_activity\n",
      "        WHERE datname = 'censo2022';\n",
      "    \n",
      "2025-09-20 16:00:09,061 INFO sqlalchemy.engine.Engine [generated in 0.00450s] {}\n",
      "2025-09-20 16:00:09,067 INFO sqlalchemy.engine.Engine DROP DATABASE IF EXISTS censo2022;\n",
      "2025-09-20 16:00:09,069 INFO sqlalchemy.engine.Engine [generated in 0.00239s] {}\n",
      "2025-09-20 16:00:09,099 INFO sqlalchemy.engine.Engine CREATE DATABASE censo2022;\n",
      "2025-09-20 16:00:09,100 INFO sqlalchemy.engine.Engine [generated in 0.00069s] {}\n",
      "2025-09-20 16:00:09,161 INFO sqlalchemy.engine.Engine ROLLBACK using DBAPI connection.rollback(), DBAPI should ignore due to autocommit mode\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(URI + DEFAULT_DATABASE, echo=True)\n",
    "\n",
    "with engine.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    terminate_sql = text(f\"\"\"\n",
    "        SELECT pg_terminate_backend(pid)\n",
    "        FROM pg_stat_activity\n",
    "        WHERE datname = '{CENSO_DATABASE}';\n",
    "    \"\"\")\n",
    "    try:\n",
    "        conn.execute(terminate_sql)\n",
    "    except ProgrammingError as e:\n",
    "        print(f\"Could not terminate connections (this is often normal): {e}\")\n",
    "    conn.execute(text(f\"DROP DATABASE IF EXISTS {CENSO_DATABASE};\"))\n",
    "    conn.execute(text(f\"CREATE DATABASE {CENSO_DATABASE};\"))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9363de9-0448-4cef-87cc-84107c3cc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backref(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(back_populates=back_populates)\n",
    "\n",
    "\n",
    "def childOf(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(\n",
    "        back_populates=back_populates,\n",
    "        cascade=\"all, delete-orphan\",\n",
    "    )\n",
    "\n",
    "def digits(name:str) -> CheckConstraint:\n",
    "    return constraint(\"id ~ '^[0-9]+$'\", name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f60461-1951-4e40-a91b-a0665447ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Households:\n",
    "    def __init__(self, urban: int, rural: int) -> None:\n",
    "        self.urban = urban\n",
    "        self.rural = rural\n",
    "\n",
    "    def __composite_values__(self) -> tuple[int, ...]:\n",
    "        return (self.urban, self.rural)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Households) and \\\n",
    "               other.urban == self.urban and \\\n",
    "               other.rural == self.rural\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "        \n",
    "    @hybrid_property\n",
    "    def total(self):\n",
    "        \"\"\"Python-side property for total households.\"\"\"\n",
    "        return self.urban + self.rural\n",
    "\n",
    "    @total.expression\n",
    "    def total(cls):\n",
    "        \"\"\"SQL-side expression for querying total households.\"\"\"\n",
    "        return cls.urban + cls.rural\n",
    "\n",
    "class Coordinate:\n",
    "    \"\"\"\n",
    "    A geographic coordinate point with longitude (lon) and latitude (lat) components.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, longitude: float, latitude: float) -> None:\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "\n",
    "    @property\n",
    "    def longitude(self) -> float:\n",
    "        return self._longitude\n",
    "\n",
    "    @longitude.setter\n",
    "    def longitude(self, value: float) -> None:\n",
    "        if not (-180 <= value <= 180):\n",
    "            raise ValueError(\n",
    "                f\"Longitude must be between -180 and 180 degrees, got {value}\"\n",
    "            )\n",
    "        self._longitude = value\n",
    "\n",
    "    @property\n",
    "    def latitude(self) -> float:\n",
    "        return self._latitude\n",
    "\n",
    "    @latitude.setter\n",
    "    def latitude(self, value: float) -> None:\n",
    "        if not (-90 <= value <= 90):\n",
    "            raise ValueError(\n",
    "                f\"Latitude must be between -90 and 90 degrees, got {value}\"\n",
    "            )\n",
    "        self._latitude = value\n",
    "\n",
    "    def __composite_values__(self) -> tuple[float, ...]:\n",
    "        return (self.longitude, self.latitude)\n",
    "\n",
    "    def __eq__(self, other: \"Coordinate\") -> bool:\n",
    "        return isinstance(other, Coordinate) and \\\n",
    "               other.longitude == self.longitude and \\\n",
    "               other.latitude == self.latitude\n",
    "        \n",
    "    def __ne__ (self, other: \"Coordinate\") -> bool:\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    @hybrid_method\n",
    "    def distance(\n",
    "        self,\n",
    "        other: \"Coordinate\",\n",
    "        metric: str = 'euclidean'\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate distance to another coordinate.\n",
    "        \n",
    "        Args:\n",
    "            other: Coordinate instance\n",
    "            metric: 'euclidean' or 'manhattan'\n",
    "        \n",
    "        Returns:\n",
    "            Distance between coordinates\n",
    "        \"\"\"\n",
    "        x = self.longitude - other.longitude\n",
    "        y = self.latitude - other.latitude\n",
    "        match metric:\n",
    "            case 'euclidean':\n",
    "                return sqrt(x**2 + y**2)\n",
    "            case 'manhattan':\n",
    "                return abs(x) + abs(y)\n",
    "            case _:\n",
    "                raise ValueError(\n",
    "                    \"Metric must be 'euclidean' or 'manhattan'\"\n",
    "                )\n",
    "\n",
    "    @distance.expression\n",
    "    def distance(\n",
    "        cls,\n",
    "        other_lon: float,\n",
    "        other_lat: float,\n",
    "        metric: str = 'euclidean'\n",
    "    ):\n",
    "        x = cls.longitude - other_lon\n",
    "        y = cls.latitude - other_lat\n",
    "        \n",
    "        match metric:\n",
    "            case 'euclidean':\n",
    "                return func.sqrt(y * x + y * y)\n",
    "            case 'manhattan':\n",
    "                return func.abs(x) + func.abs(y)\n",
    "            case _:\n",
    "                raise ValueError(\n",
    "                    \"Metric must be 'euclidean' or 'manhattan'\"\n",
    "                )\n",
    "\n",
    "\n",
    "class Biomes:\n",
    "    default: dict[str, float] = {\n",
    "        biome: 0.0 for biome in [\n",
    "            'amazon_rainforest',\n",
    "            'atlantic_forest',\n",
    "            'caatinga',\n",
    "            'cerrado',\n",
    "            'pantanal',\n",
    "            'pampas'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.distribution = kwargs\n",
    "\n",
    "    def __composite_values__(self) -> tuple[float, ...]:\n",
    "        return tuple(getattr(self, biome) for biome in self.default.keys())\n",
    "\n",
    "    def __eq__(self, other: \"Biomes\") -> bool:\n",
    "        return self.__composite_values__() == other.__composite_values__()\n",
    "\n",
    "    def __ne__()\n",
    "\n",
    "    @property\n",
    "    def distribution(self) -> dict[str, float]:\n",
    "        return {biome: getattr(self, biome) for biome in self.default.keys()}\n",
    "\n",
    "\n",
    "    @distribution.setter\n",
    "    def distribution(self, values: dict[str, float]) -> None:\n",
    "        merged_values = {**self.default, **values}\n",
    "\n",
    "        # Validation\n",
    "        invalid_keys = set(merged_values.keys()) - set(self.default.keys())\n",
    "        if invalid_keys:\n",
    "            raise ValueError(\n",
    "                f\"Invalid biome types: {invalid_keys}. Valid types are: {list(self.default.keys())}\"\n",
    "            )\n",
    "        total = sum(merged_values.values())\n",
    "        if not (99.9 <= total <= 100.1):\n",
    "            raise ValueError(\n",
    "                f\"Invalid biome distribution, totalling {total:.1f}%\"\n",
    "            )\n",
    "        self._distribution = merged_values\n",
    "\n",
    "        for biome_type, value in merged_values.items():\n",
    "            setattr(self, biome_type, value)\n",
    "\n",
    "    @property\n",
    "    def total(self) -> float:\n",
    "        return sum(getattr(self, biome) for biome in self.default.keys())\n",
    "\n",
    "    @classmethod\n",
    "    def toList(cls) -> list[str]:\n",
    "        return list(cls.default.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198f174f-0553-4092-8f21-9d1f041c0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Region(Base):\n",
    "    __tablename__: str = \"regions\"\n",
    "\n",
    "    # Attributes\n",
    "    id: Mapped[str] = column(\n",
    "        String(1),\n",
    "        digits(\"ck_region_id\"),\n",
    "        primary_key=True\n",
    "    )\n",
    "    name: Mapped[str] = column(unique=True)\n",
    "\n",
    "    # Relationships\n",
    "    states: Mapped[list[\"State\"]] = childOf('region')\n",
    "\n",
    "\n",
    "class State(Base):\n",
    "    __tablename__: str = \"states\"\n",
    "\n",
    "    # Attributes\n",
    "    id: Mapped[str] = column(String(1), digits(\"ck_state_id\"))\n",
    "    name: Mapped[str] = column(unique=True)\n",
    "    uf: Mapped[str] = column(String(2), unique=True)\n",
    "    location: Mapped[Coordinate] = composite(\n",
    "        column(\"longitude\", Float),\n",
    "        column(\"latitude\", Float)\n",
    "    )\n",
    "    area: Mapped[float]\n",
    "    biome_distribution: Mapped[Biomes] = composite(\n",
    "        *[column(biome, Float, default=0.0) for biome in Biomes.toList()]\n",
    "    )\n",
    "\n",
    "    # Foreign keys\n",
    "    region_id: Mapped[str] = column(fk(\"regions.id\"))\n",
    "\n",
    "    # Relationships\n",
    "    region: Mapped[\"Region\"] = backref(\"states\")\n",
    "    cities: Mapped[list[\"City\"]] = childOf(\"state\")\n",
    "\n",
    "    __table_args__: tuple[pkc, unique,] = (\n",
    "        pkc(\"region_id\", \"id\"),\n",
    "        unique('longitude', 'latitude', name='uq_state_location'),\n",
    "    )\n",
    "\n",
    "\n",
    "class City(Base):\n",
    "    __tablename__: str = \"cities\"\n",
    "\n",
    "    # Attributes\n",
    "    id: Mapped[str] = column(String(5), digits(\"ck_city_id\"))\n",
    "    name: Mapped[str]\n",
    "    is_capital: Mapped[bool] = column(default=False, server_default='false')\n",
    "    location: Mapped[Coordinate] = composite(\n",
    "        column(\"longitude\", Float),\n",
    "        column(\"latitude\", Float)\n",
    "    )\n",
    "    ddd: Mapped[str] = column(String(2), digits(\"ck_city_ddd\"))\n",
    "    households: Mapped[Households] = composite(\n",
    "        column(\"urban\", Integer),\n",
    "        column(\"rural\", Integer)\n",
    "    )\n",
    "    population_race: Mapped[dict | None] = column(JSON)\n",
    "    population_education: Mapped[dict | None] = column(JSON)\n",
    "    \n",
    "\n",
    "    # Foreign keys\n",
    "    timezone_name: Mapped[str] = column(fk(\"timezones.name\"))\n",
    "    region_id: Mapped[str]\n",
    "    state_id: Mapped[str]\n",
    "\n",
    "    # Relationships\n",
    "    timezone: Mapped[\"Timezone\"] = backref(\"cities\")\n",
    "    state: Mapped[\"State\"] = backref(\"cities\")\n",
    "\n",
    "    @hybrid_property\n",
    "    def ibge_code(self) -> str:\n",
    "        \"\"\"Python-side property to get the IBGE code.\"\"\"\n",
    "        return self.region_id + self.state_id + self.id\n",
    "\n",
    "    @ibge_code.expression\n",
    "    def ibge_code(cls):\n",
    "        \"\"\"SQL-side expression for querying.\"\"\"\n",
    "        return cast(\n",
    "            func.concat(\n",
    "                # Join to State to get the region ID\n",
    "                cast(cls.region_id, String),\n",
    "                cast(cls.state_id, String),\n",
    "                cast(cls.id, String)\n",
    "            ),\n",
    "            BigInteger\n",
    "        )\n",
    "\n",
    "    __table_args__: tuple[pkc, fkc, unique, ] = (\n",
    "        pkc(\"region_id\", \"state_id\", \"id\"),\n",
    "        fkc(\n",
    "            ['region_id', 'state_id'],\n",
    "            ['states.region_id', 'states.id'],\n",
    "            name='fk_region_composite'\n",
    "        ),\n",
    "        unique(\"longitude\", \"latitude\", name=\"uq_city_location\"),\n",
    "        Index(\n",
    "            'state_capitals_index',\n",
    "            'region_id', 'state_id',\n",
    "            postgresql_where=text('is_capital'),\n",
    "            unique=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class Timezone(Base):\n",
    "    __tablename__: str = \"timezones\"\n",
    "\n",
    "    # Attributes\n",
    "    name: Mapped[str] = column(primary_key=True)\n",
    "    utc_offset: Mapped[int]\n",
    "\n",
    "    # Relationships\n",
    "    cities: Mapped[list[\"City\"]] = backref('timezone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a4df84-58fa-458a-a1a3-e5707bad84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 16:00:09,257 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-20 16:00:09,260 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-20 16:00:09,262 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-20 16:00:09,263 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-20 16:00:09,265 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-20 16:00:09,266 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-20 16:00:09,268 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:09,276 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-20 16:00:09,277 INFO sqlalchemy.engine.Engine [generated in 0.00103s] {'table_name': 'regions', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-20 16:00:09,281 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-20 16:00:09,281 INFO sqlalchemy.engine.Engine [cached since 0.005411s ago] {'table_name': 'states', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-20 16:00:09,283 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-20 16:00:09,284 INFO sqlalchemy.engine.Engine [cached since 0.007999s ago] {'table_name': 'cities', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-20 16:00:09,286 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-20 16:00:09,287 INFO sqlalchemy.engine.Engine [cached since 0.01093s ago] {'table_name': 'timezones', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-20 16:00:09,292 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE regions (\n",
      "\tid VARCHAR(1) NOT NULL CONSTRAINT ck_region_id CHECK (id ~ '^[0-9]+$'), \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tPRIMARY KEY (id), \n",
      "\tUNIQUE (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-20 16:00:09,378 INFO sqlalchemy.engine.Engine [no key 0.08565s] {}\n",
      "2025-09-20 16:00:09,397 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE timezones (\n",
      "\tname VARCHAR NOT NULL, \n",
      "\tutc_offset INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-20 16:00:09,398 INFO sqlalchemy.engine.Engine [no key 0.00110s] {}\n",
      "2025-09-20 16:00:09,407 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE states (\n",
      "\tid VARCHAR(1) NOT NULL CONSTRAINT ck_state_id CHECK (id ~ '^[0-9]+$'), \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tuf VARCHAR(2) NOT NULL, \n",
      "\tlongitude FLOAT, \n",
      "\tlatitude FLOAT, \n",
      "\tarea FLOAT NOT NULL, \n",
      "\tamazon_rainforest FLOAT, \n",
      "\tatlantic_forest FLOAT, \n",
      "\tcaatinga FLOAT, \n",
      "\tcerrado FLOAT, \n",
      "\tpantanal FLOAT, \n",
      "\tpampas FLOAT, \n",
      "\tregion_id VARCHAR(1) NOT NULL, \n",
      "\tPRIMARY KEY (region_id, id), \n",
      "\tCONSTRAINT uq_state_location UNIQUE (longitude, latitude), \n",
      "\tUNIQUE (name), \n",
      "\tUNIQUE (uf), \n",
      "\tFOREIGN KEY(region_id) REFERENCES regions (id)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-20 16:00:09,409 INFO sqlalchemy.engine.Engine [no key 0.00258s] {}\n",
      "2025-09-20 16:00:09,432 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE cities (\n",
      "\tid VARCHAR(5) NOT NULL CONSTRAINT ck_city_id CHECK (id ~ '^[0-9]+$'), \n",
      "\tname VARCHAR NOT NULL, \n",
      "\tis_capital BOOLEAN DEFAULT 'false' NOT NULL, \n",
      "\tlongitude FLOAT, \n",
      "\tlatitude FLOAT, \n",
      "\tddd VARCHAR(2) NOT NULL CONSTRAINT ck_city_ddd CHECK (id ~ '^[0-9]+$'), \n",
      "\turban INTEGER, \n",
      "\trural INTEGER, \n",
      "\tpopulation_race JSON, \n",
      "\tpopulation_education JSON, \n",
      "\ttimezone_name VARCHAR NOT NULL, \n",
      "\tregion_id VARCHAR NOT NULL, \n",
      "\tstate_id VARCHAR NOT NULL, \n",
      "\tPRIMARY KEY (region_id, state_id, id), \n",
      "\tCONSTRAINT fk_region_composite FOREIGN KEY(region_id, state_id) REFERENCES states (region_id, id), \n",
      "\tCONSTRAINT uq_city_location UNIQUE (longitude, latitude), \n",
      "\tFOREIGN KEY(timezone_name) REFERENCES timezones (name)\n",
      ")\n",
      "\n",
      "\n",
      "2025-09-20 16:00:09,433 INFO sqlalchemy.engine.Engine [no key 0.00093s] {}\n",
      "2025-09-20 16:00:09,449 INFO sqlalchemy.engine.Engine CREATE UNIQUE INDEX state_capitals_index ON cities (region_id, state_id) WHERE is_capital\n",
      "2025-09-20 16:00:09,450 INFO sqlalchemy.engine.Engine [no key 0.00081s] {}\n",
      "2025-09-20 16:00:09,456 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(URI + CENSO_DATABASE, echo=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cf92cf-898b-4989-a0a7-438390d5c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 16:00:09,490 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:09,494 INFO sqlalchemy.engine.Engine INSERT INTO regions (id, name) VALUES (%(id__0)s, %(name__0)s), (%(id__1)s, %(name__1)s), (%(id__2)s, %(name__2)s), (%(id__3)s, %(name__3)s), (%(id__4)s, %(name__4)s)\n",
      "2025-09-20 16:00:09,495 INFO sqlalchemy.engine.Engine [generated in 0.00009s (insertmanyvalues) 1/1 (unordered)] {'name__0': 'Norte', 'id__0': '1', 'name__1': 'Nordeste', 'id__1': '2', 'name__2': 'Sudeste', 'id__2': '3', 'name__3': 'Sul', 'id__3': '4', 'name__4': 'Centro-Oeste', 'id__4': '5'}\n",
      "2025-09-20 16:00:09,499 INFO sqlalchemy.engine.Engine INSERT INTO timezones (name, utc_offset) VALUES (%(name__0)s, %(utc_offset__0)s), (%(name__1)s, %(utc_offset__1)s), (%(name__2)s, %(utc_offset__2)s), (%(name__3)s, %(utc_offset__3)s), (%(name__4)s, %(utc_offset__4)s), (%(name__5)s, %(utc_offset__5)s), (%(name__6)s, %(utc_offset__6)s)\n",
      "2025-09-20 16:00:09,499 INFO sqlalchemy.engine.Engine [generated in 0.00008s (insertmanyvalues) 1/1 (unordered)] {'utc_offset__0': -2, 'name__0': 'America/Noronha', 'utc_offset__1': -3, 'name__1': 'America/Sao_Paulo', 'utc_offset__2': -3, 'name__2': 'America/Brasilia', 'utc_offset__3': -3, 'name__3': 'America/Recife', 'utc_offset__4': -4, 'name__4': 'America/Porto_Velho', 'utc_offset__5': -4, 'name__5': 'America/Manaus', 'utc_offset__6': -5, 'name__6': 'America/Rio_Branco'}\n",
      "2025-09-20 16:00:09,501 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "# 1. Region Data\n",
    "regions_data = [\"Norte\", \"Nordeste\", \"Sudeste\", \"Sul\", \"Centro-Oeste\"]\n",
    "\n",
    "# 2. Timezone Data\n",
    "timezones_data = [\n",
    "    ('America/Noronha', -2),\n",
    "    ('America/Sao_Paulo', -3),\n",
    "    ('America/Brasilia', -3),\n",
    "    ('America/Recife', -3),\n",
    "    ('America/Porto_Velho', -4),\n",
    "    ('America/Manaus', -4),\n",
    "    ('America/Rio_Branco', -5),\n",
    "]\n",
    "\n",
    "with Session() as session:\n",
    "    # Populate the Regions table\n",
    "    regions = [\n",
    "        Region(id=str(idx), name=name) for idx, name in enumerate(regions_data, start=1)\n",
    "    ]\n",
    "    session.add_all(regions)\n",
    "\n",
    "    # Populate the Timezones table\n",
    "    timezones = [Timezone(name=name, utc_offset=offset) for name, offset in timezones_data]\n",
    "    session.add_all(timezones)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4996ad7-1a1e-450d-8f42-f9fa0b1d128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 16:00:09,523 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:09,527 INFO sqlalchemy.engine.Engine INSERT INTO states (id, name, uf, longitude, latitude, area, amazon_rainforest, atlantic_forest, caatinga, cerrado, pantanal, pampas, region_id) VALUES (%(id__0)s, %(name__0)s, %(uf__0)s, %(longitude__0)s, %(latitude__0)s, %(area__0)s, %(amazon_rainf ... 5907 characters truncated ... orest__26)s, %(caatinga__26)s, %(cerrado__26)s, %(pantanal__26)s, %(pampas__26)s, %(region_id__26)s)\n",
      "2025-09-20 16:00:09,528 INFO sqlalchemy.engine.Engine [generated in 0.00034s (insertmanyvalues) 1/1 (unordered)] {'uf__0': 'RO', 'id__0': '1', 'area__0': 237754.171, 'latitude__0': -10.83, 'amazon_rainforest__0': 99.0, 'region_id__0': '1', 'atlantic_forest__0': 0.0, 'cerrado__0': 1.0, 'caatinga__0': 0.0, 'name__0': 'Rondônia', 'pampas__0': 0.0, 'longitude__0': -63.34, 'pantanal__0': 0.0, 'uf__1': 'AC', 'id__1': '2', 'area__1': 164082.96, 'latitude__1': -8.77, 'amazon_rainforest__1': 100.0, 'region_id__1': '1', 'atlantic_forest__1': 0.0, 'cerrado__1': 0.0, 'caatinga__1': 0.0, 'name__1': 'Acre', 'pampas__1': 0.0, 'longitude__1': -70.55, 'pantanal__1': 0.0, 'uf__2': 'AM', 'id__2': '3', 'area__2': 1558706.127, 'latitude__2': -3.47, 'amazon_rainforest__2': 100.0, 'region_id__2': '1', 'atlantic_forest__2': 0.0, 'cerrado__2': 0.0, 'caatinga__2': 0.0, 'name__2': 'Amazonas', 'pampas__2': 0.0, 'longitude__2': -65.1, 'pantanal__2': 0.0, 'uf__3': 'RR', 'id__3': '4', 'area__3': 223505.385, 'latitude__3': 1.99, 'amazon_rainforest__3': 100.0, 'region_id__3': '1', 'atlantic_forest__3': 0.0, 'cerrado__3': 0.0, 'caatinga__3': 0.0, 'name__3': 'Roraima', 'pampas__3': 0.0 ... 251 parameters truncated ... 'area__23': 357142.01, 'latitude__23': -20.51, 'amazon_rainforest__23': 0.0, 'region_id__23': '5', 'atlantic_forest__23': 14.0, 'cerrado__23': 61.0, 'caatinga__23': 0.0, 'name__23': 'Mato Grosso do Sul', 'pampas__23': 0.0, 'longitude__23': -54.54, 'pantanal__23': 25.0, 'uf__24': 'MT', 'id__24': '1', 'area__24': 903208.362, 'latitude__24': -12.64, 'amazon_rainforest__24': 54.0, 'region_id__24': '5', 'atlantic_forest__24': 0.0, 'cerrado__24': 39.0, 'caatinga__24': 0.0, 'name__24': 'Mato Grosso', 'pampas__24': 0.0, 'longitude__24': -55.42, 'pantanal__24': 7.0, 'uf__25': 'GO', 'id__25': '2', 'area__25': 340242.86, 'latitude__25': -15.98, 'amazon_rainforest__25': 0.0, 'region_id__25': '5', 'atlantic_forest__25': 3.0, 'cerrado__25': 97.0, 'caatinga__25': 0.0, 'name__25': 'Goias', 'pampas__25': 0.0, 'longitude__25': -49.86, 'pantanal__25': 0.0, 'uf__26': 'DF', 'id__26': '3', 'area__26': 5760.783, 'latitude__26': -15.83, 'amazon_rainforest__26': 0.0, 'region_id__26': '5', 'atlantic_forest__26': 0.0, 'cerrado__26': 100.0, 'caatinga__26': 0.0, 'name__26': 'Distrito Federal', 'pampas__26': 0.0, 'longitude__26': -47.86, 'pantanal__26': 0.0}\n",
      "2025-09-20 16:00:09,534 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(**FILES['states'])\n",
    "df.fillna(0.0, inplace=True)\n",
    "BIOME_COLUMN_MAPPING = {\n",
    "    'Amazônia': 'amazon_rainforest',\n",
    "    'Mata Atlântica': 'atlantic_forest',\n",
    "    'Caatinga': 'caatinga',\n",
    "    'Cerrado': 'cerrado',\n",
    "    'Pantanal': 'pantanal',\n",
    "    'Pampa': 'pampas'\n",
    "}\n",
    "csv_biome_cols = df.columns[8:].tolist()\n",
    "\n",
    "states_to_insert = []\n",
    "for _, row in df.iterrows():\n",
    "    code_str = str(row['codigouf'])\n",
    "    state_data = {\n",
    "        'region_id': code_str[0],\n",
    "        'id': code_str[1],\n",
    "        'uf': row['uf'],\n",
    "        'name': row['estado'],\n",
    "        'longitude': row['long'],\n",
    "        'latitude': row['lat'],\n",
    "        'area': row['Area']\n",
    "    }\n",
    "\n",
    "    for csv_col in csv_biome_cols:\n",
    "        model_attr = BIOME_COLUMN_MAPPING.get(csv_col)\n",
    "        state_data[model_attr] = row[csv_col]\n",
    "\n",
    "    states_to_insert.append(state_data)\n",
    "\n",
    "\n",
    "with Session() as session:\n",
    "    session.bulk_insert_mappings(State, states_to_insert)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4883486c-e36f-49c0-b296-569f467c39bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 16:00:09,563 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:09,567 INFO sqlalchemy.engine.Engine SELECT states.region_id, states.id, states.uf \n",
      "FROM states\n",
      "2025-09-20 16:00:09,567 INFO sqlalchemy.engine.Engine [generated in 0.00081s] {}\n",
      "Phase 1: Loading initial city data...\n",
      "2025-09-20 16:00:10,204 INFO sqlalchemy.engine.Engine INSERT INTO cities (id, name, is_capital, longitude, latitude, ddd, timezone_name, region_id, state_id) VALUES (%(id__0)s, %(name__0)s, %(is_capital__0)s, %(longitude__0)s, %(latitude__0)s, %(ddd__0)s, %(timezone_name__0)s, %(region_id__0)s, %(state_ ... 165769 characters truncated ... 9)s, %(latitude__999)s, %(ddd__999)s, %(timezone_name__999)s, %(region_id__999)s, %(state_id__999)s)\n",
      "2025-09-20 16:00:10,205 INFO sqlalchemy.engine.Engine [generated in 0.03027s (insertmanyvalues) 1/6 (unordered)] {'id__0': '00050', 'latitude__0': -16.7573, 'region_id__0': '5', 'state_id__0': '2', 'name__0': 'Abadia de Goiás', 'timezone_name__0': 'America/Sao_Paulo', 'is_capital__0': False, 'longitude__0': -49.4412, 'ddd__0': '62', 'id__1': '00104', 'latitude__1': -18.4831, 'region_id__1': '3', 'state_id__1': '1', 'name__1': 'Abadia dos Dourados', 'timezone_name__1': 'America/Sao_Paulo', 'is_capital__1': False, 'longitude__1': -47.3916, 'ddd__1': '34', 'id__2': '00100', 'latitude__2': -16.197, 'region_id__2': '5', 'state_id__2': '2', 'name__2': 'Abadiânia', 'timezone_name__2': 'America/Sao_Paulo', 'is_capital__2': False, 'longitude__2': -48.7057, 'ddd__2': '62', 'id__3': '00203', 'latitude__3': -19.1551, 'region_id__3': '3', 'state_id__3': '1', 'name__3': 'Abaeté', 'timezone_name__3': 'America/Sao_Paulo', 'is_capital__3': False, 'longitude__3': -45.4444, 'ddd__3': '37', 'id__4': '00107', 'latitude__4': -1.72183, 'region_id__4': '1', 'state_id__4': '5', 'name__4': 'Abaetetuba', 'timezone_name__4': 'America/Sao_Paulo', 'is_capital__4': False, 'longitude__4': -48.8788, 'ddd__4': '91', 'id__5': '00101', 'latitude__5': -7.34588, 'region_id__5': '2', 'state_id__5': '3', 'name__5': 'Abaiara' ... 8900 parameters truncated ... 'name__994': 'Campos Novos', 'timezone_name__994': 'America/Sao_Paulo', 'is_capital__994': False, 'longitude__994': -51.2276, 'ddd__994': '49', 'id__995': '09809', 'latitude__995': -22.602, 'region_id__995': '3', 'state_id__995': '5', 'name__995': 'Campos Novos Paulista', 'timezone_name__995': 'America/Sao_Paulo', 'is_capital__995': False, 'longitude__995': -49.9987, 'ddd__995': '14', 'id__996': '02701', 'latitude__996': -7.06761, 'region_id__996': '2', 'state_id__996': '3', 'name__996': 'Campos Sales', 'timezone_name__996': 'America/Sao_Paulo', 'is_capital__996': False, 'longitude__996': -40.3687, 'ddd__996': '88', 'id__997': '04953', 'latitude__997': -14.2442, 'region_id__997': '5', 'state_id__997': '2', 'name__997': 'Campos Verdes', 'timezone_name__997': 'America/Sao_Paulo', 'is_capital__997': False, 'longitude__997': -49.6528, 'ddd__997': '62', 'id__998': '03603', 'latitude__998': -7.40545, 'region_id__998': '2', 'state_id__998': '6', 'name__998': 'Camutanga', 'timezone_name__998': 'America/Sao_Paulo', 'is_capital__998': False, 'longitude__998': -35.2664, 'ddd__998': '81', 'id__999': '11903', 'latitude__999': -21.0232, 'region_id__999': '3', 'state_id__999': '1', 'name__999': 'Cana Verde', 'timezone_name__999': 'America/Sao_Paulo', 'is_capital__999': False, 'longitude__999': -45.1801, 'ddd__999': '35'}\n",
      "2025-09-20 16:00:10,300 INFO sqlalchemy.engine.Engine INSERT INTO cities (id, name, is_capital, longitude, latitude, ddd, timezone_name, region_id, state_id) VALUES (%(id__0)s, %(name__0)s, %(is_capital__0)s, %(longitude__0)s, %(latitude__0)s, %(ddd__0)s, %(timezone_name__0)s, %(region_id__0)s, %(state_ ... 165769 characters truncated ... 9)s, %(latitude__999)s, %(ddd__999)s, %(timezone_name__999)s, %(region_id__999)s, %(state_id__999)s)\n",
      "2025-09-20 16:00:10,301 INFO sqlalchemy.engine.Engine [insertmanyvalues 2/6 (unordered)] {'id__0': '11705', 'latitude__0': -20.6869, 'region_id__0': '3', 'state_id__0': '1', 'name__0': 'Canaã', 'timezone_name__0': 'America/Sao_Paulo', 'is_capital__0': False, 'longitude__0': -42.6167, 'ddd__0': '31', 'id__1': '02152', 'latitude__1': -6.49659, 'region_id__1': '1', 'state_id__1': '5', 'name__1': 'Canaã dos Carajás', 'timezone_name__1': 'America/Sao_Paulo', 'is_capital__1': False, 'longitude__1': -49.8776, 'ddd__1': '94', 'id__2': '02694', 'latitude__2': -11.0556, 'region_id__2': '5', 'state_id__2': '1', 'name__2': 'Canabrava do Norte', 'timezone_name__2': 'America/Porto_Velho', 'is_capital__2': False, 'longitude__2': -51.8209, 'ddd__2': '66', 'id__3': '09908', 'latitude__3': -25.0144, 'region_id__3': '3', 'state_id__3': '5', 'name__3': 'Cananéia', 'timezone_name__3': 'America/Sao_Paulo', 'is_capital__3': False, 'longitude__3': -47.9341, 'ddd__3': '13', 'id__4': '01605', 'latitude__4': -9.11932, 'region_id__4': '2', 'state_id__4': '7', 'name__4': 'Canapi', 'timezone_name__4': 'America/Sao_Paulo', 'is_capital__4': False, 'longitude__4': -37.5967, 'ddd__4': '82', 'id__5': '06105', 'latitude__5': -13.0725, 'region_id__5': '2', 'state_id__5': '9', 'name__5': 'Canápolis' ... 8900 parameters truncated ... 'name__994': 'Guapimirim', 'timezone_name__994': 'America/Sao_Paulo', 'is_capital__994': False, 'longitude__994': -42.9895, 'ddd__994': '21', 'id__995': '09005', 'latitude__995': -23.5203, 'region_id__995': '4', 'state_id__995': '1', 'name__995': 'Guapirama', 'timezone_name__995': 'America/Sao_Paulo', 'is_capital__995': False, 'longitude__995': -50.0407, 'ddd__995': '43', 'id__996': '09200', 'latitude__996': -16.8297, 'region_id__996': '5', 'state_id__996': '2', 'name__996': 'Guapó', 'timezone_name__996': 'America/Sao_Paulo', 'is_capital__996': False, 'longitude__996': -49.5345, 'ddd__996': '62', 'id__997': '09407', 'latitude__997': -28.8399, 'region_id__997': '4', 'state_id__997': '3', 'name__997': 'Guaporé', 'timezone_name__997': 'America/Sao_Paulo', 'is_capital__997': False, 'longitude__997': -51.8895, 'ddd__997': '54', 'id__998': '09104', 'latitude__998': -23.3402, 'region_id__998': '4', 'state_id__998': '1', 'name__998': 'Guaporema', 'timezone_name__998': 'America/Sao_Paulo', 'is_capital__998': False, 'longitude__998': -52.7786, 'ddd__998': '44', 'id__999': '17703', 'latitude__999': -20.4302, 'region_id__999': '3', 'state_id__999': '5', 'name__999': 'Guará', 'timezone_name__999': 'America/Sao_Paulo', 'is_capital__999': False, 'longitude__999': -47.8236, 'ddd__999': '16'}\n",
      "2025-09-20 16:00:10,383 INFO sqlalchemy.engine.Engine INSERT INTO cities (id, name, is_capital, longitude, latitude, ddd, timezone_name, region_id, state_id) VALUES (%(id__0)s, %(name__0)s, %(is_capital__0)s, %(longitude__0)s, %(latitude__0)s, %(ddd__0)s, %(timezone_name__0)s, %(region_id__0)s, %(state_ ... 165769 characters truncated ... 9)s, %(latitude__999)s, %(ddd__999)s, %(timezone_name__999)s, %(region_id__999)s, %(state_id__999)s)\n",
      "2025-09-20 16:00:10,384 INFO sqlalchemy.engine.Engine [insertmanyvalues 3/6 (unordered)] {'id__0': '06301', 'latitude__0': -6.85064, 'region_id__0': '2', 'state_id__0': '5', 'name__0': 'Guarabira', 'timezone_name__0': 'America/Sao_Paulo', 'is_capital__0': False, 'longitude__0': -35.485, 'ddd__0': '83', 'id__1': '17802', 'latitude__1': -21.0292, 'region_id__1': '3', 'state_id__1': '5', 'name__1': 'Guaraçaí', 'timezone_name__1': 'America/Sao_Paulo', 'is_capital__1': False, 'longitude__1': -51.2119, 'ddd__1': '18', 'id__2': '17901', 'latitude__2': -20.4977, 'region_id__2': '3', 'state_id__2': '5', 'name__2': 'Guaraci', 'timezone_name__2': 'America/Sao_Paulo', 'is_capital__2': False, 'longitude__2': -48.9391, 'ddd__2': '17', 'id__3': '09203', 'latitude__3': -22.9694, 'region_id__3': '4', 'state_id__3': '1', 'name__3': 'Guaraci', 'timezone_name__3': 'America/Sao_Paulo', 'is_capital__3': False, 'longitude__3': -51.6504, 'ddd__3': '43', 'id__4': '28204', 'latitude__4': -20.5716, 'region_id__4': '3', 'state_id__4': '1', 'name__4': 'Guaraciaba', 'timezone_name__4': 'America/Sao_Paulo', 'is_capital__4': False, 'longitude__4': -43.0094, 'ddd__4': '31', 'id__5': '06405', 'latitude__5': -26.6042, 'region_id__5': '4', 'state_id__5': '2', 'name__5': 'Guaraciaba' ... 8900 parameters truncated ... 'name__994': 'Mata Roma', 'timezone_name__994': 'America/Sao_Paulo', 'is_capital__994': False, 'longitude__994': -43.1112, 'ddd__994': '98', 'id__995': '40555', 'latitude__995': -15.6869, 'region_id__995': '3', 'state_id__995': '1', 'name__995': 'Mata Verde', 'timezone_name__995': 'America/Sao_Paulo', 'is_capital__995': False, 'longitude__995': -40.7366, 'ddd__995': '33', 'id__996': '29302', 'latitude__996': -21.6025, 'region_id__996': '3', 'state_id__996': '5', 'name__996': 'Matão', 'timezone_name__996': 'America/Sao_Paulo', 'is_capital__996': False, 'longitude__996': -48.364, 'ddd__996': '16', 'id__997': '09305', 'latitude__997': -6.59673, 'region_id__997': '2', 'state_id__997': '5', 'name__997': 'Mataraca', 'timezone_name__997': 'America/Sao_Paulo', 'is_capital__997': False, 'longitude__997': -35.0531, 'ddd__997': '83', 'id__998': '12702', 'latitude__998': -10.5464, 'region_id__998': '1', 'state_id__998': '7', 'name__998': 'Mateiros', 'timezone_name__998': 'America/Sao_Paulo', 'is_capital__998': False, 'longitude__998': -46.4168, 'ddd__998': '63', 'id__999': '15606', 'latitude__999': -25.2496, 'region_id__999': '4', 'state_id__999': '1', 'name__999': 'Matelândia', 'timezone_name__999': 'America/Sao_Paulo', 'is_capital__999': False, 'longitude__999': -53.9935, 'ddd__999': '45'}\n",
      "2025-09-20 16:00:10,458 INFO sqlalchemy.engine.Engine INSERT INTO cities (id, name, is_capital, longitude, latitude, ddd, timezone_name, region_id, state_id) VALUES (%(id__0)s, %(name__0)s, %(is_capital__0)s, %(longitude__0)s, %(latitude__0)s, %(ddd__0)s, %(timezone_name__0)s, %(region_id__0)s, %(state_ ... 165769 characters truncated ... 9)s, %(latitude__999)s, %(ddd__999)s, %(timezone_name__999)s, %(region_id__999)s, %(state_id__999)s)\n",
      "2025-09-20 16:00:10,459 INFO sqlalchemy.engine.Engine [insertmanyvalues 4/6 (unordered)] {'id__0': '40605', 'latitude__0': -18.4699, 'region_id__0': '3', 'state_id__0': '1', 'name__0': 'Materlândia', 'timezone_name__0': 'America/Sao_Paulo', 'is_capital__0': False, 'longitude__0': -43.0579, 'ddd__0': '33', 'id__1': '40704', 'latitude__1': -19.9794, 'region_id__1': '3', 'state_id__1': '1', 'name__1': 'Mateus Leme', 'timezone_name__1': 'America/Sao_Paulo', 'is_capital__1': False, 'longitude__1': -44.4318, 'ddd__1': '31', 'id__2': '71501', 'latitude__2': -18.59, 'region_id__2': '3', 'state_id__2': '1', 'name__2': 'Mathias Lobato', 'timezone_name__2': 'America/Sao_Paulo', 'is_capital__2': False, 'longitude__2': -41.9166, 'ddd__2': '33', 'id__3': '40803', 'latitude__3': -21.869, 'region_id__3': '3', 'state_id__3': '1', 'name__3': 'Matias Barbosa', 'timezone_name__3': 'America/Sao_Paulo', 'is_capital__3': False, 'longitude__3': -43.3135, 'ddd__3': '32', 'id__4': '40852', 'latitude__4': -14.8563, 'region_id__4': '3', 'state_id__4': '1', 'name__4': 'Matias Cardoso', 'timezone_name__4': 'America/Sao_Paulo', 'is_capital__4': False, 'longitude__4': -43.9146, 'ddd__4': '38', 'id__5': '06100', 'latitude__5': -3.71492, 'region_id__5': '2', 'state_id__5': '2', 'name__5': 'Matias Olímpio' ... 8900 parameters truncated ... 'name__994': 'Pracinha', 'timezone_name__994': 'America/Sao_Paulo', 'is_capital__994': False, 'longitude__994': -51.0868, 'ddd__994': '18', 'id__995': '00550', 'latitude__995': 1.74543, 'region_id__995': '1', 'state_id__995': '6', 'name__995': 'Pracuúba', 'timezone_name__995': 'America/Sao_Paulo', 'is_capital__995': False, 'longitude__995': -50.7892, 'ddd__995': '96', 'id__996': '25501', 'latitude__996': -17.3364, 'region_id__996': '2', 'state_id__996': '9', 'name__996': 'Prado', 'timezone_name__996': 'America/Sao_Paulo', 'is_capital__996': False, 'longitude__996': -39.2227, 'ddd__996': '73', 'id__997': '20333', 'latitude__997': -23.0357, 'region_id__997': '4', 'state_id__997': '1', 'name__997': 'Prado Ferreira', 'timezone_name__997': 'America/Sao_Paulo', 'is_capital__997': False, 'longitude__997': -51.4429, 'ddd__997': '43', 'id__998': '40903', 'latitude__998': -21.3626, 'region_id__998': '3', 'state_id__998': '5', 'name__998': 'Pradópolis', 'timezone_name__998': 'America/Sao_Paulo', 'is_capital__998': False, 'longitude__998': -48.0679, 'ddd__998': '16', 'id__999': '52709', 'latitude__999': -21.0597, 'region_id__999': '3', 'state_id__999': '1', 'name__999': 'Prados', 'timezone_name__999': 'America/Sao_Paulo', 'is_capital__999': False, 'longitude__999': -44.0778, 'ddd__999': '32'}\n",
      "2025-09-20 16:00:10,541 INFO sqlalchemy.engine.Engine INSERT INTO cities (id, name, is_capital, longitude, latitude, ddd, timezone_name, region_id, state_id) VALUES (%(id__0)s, %(name__0)s, %(is_capital__0)s, %(longitude__0)s, %(latitude__0)s, %(ddd__0)s, %(timezone_name__0)s, %(region_id__0)s, %(state_ ... 165769 characters truncated ... 9)s, %(latitude__999)s, %(ddd__999)s, %(timezone_name__999)s, %(region_id__999)s, %(state_id__999)s)\n",
      "2025-09-20 16:00:10,543 INFO sqlalchemy.engine.Engine [insertmanyvalues 5/6 (unordered)] {'id__0': '41000', 'latitude__0': -24.0084, 'region_id__0': '3', 'state_id__0': '5', 'name__0': 'Praia Grande', 'timezone_name__0': 'America/Sao_Paulo', 'is_capital__0': False, 'longitude__0': -46.4121, 'ddd__0': '13', 'id__1': '13807', 'latitude__1': -29.1918, 'region_id__1': '4', 'state_id__1': '2', 'name__1': 'Praia Grande', 'timezone_name__1': 'America/Sao_Paulo', 'is_capital__1': False, 'longitude__1': -49.9525, 'ddd__1': '48', 'id__2': '18303', 'latitude__2': -5.39281, 'region_id__2': '1', 'state_id__2': '7', 'name__2': 'Praia Norte', 'timezone_name__2': 'America/Sao_Paulo', 'is_capital__2': False, 'longitude__2': -47.8111, 'ddd__2': '63', 'id__3': '06005', 'latitude__3': -1.798, 'region_id__3': '1', 'state_id__3': '5', 'name__3': 'Prainha', 'timezone_name__3': 'America/Sao_Paulo', 'is_capital__3': False, 'longitude__3': -53.4779, 'ddd__3': '93', 'id__4': '20358', 'latitude__4': -26.0209, 'region_id__4': '4', 'state_id__4': '1', 'name__4': 'Pranchita', 'timezone_name__4': 'America/Sao_Paulo', 'is_capital__4': False, 'longitude__4': -53.7397, 'ddd__4': '46', 'id__5': '52808', 'latitude__5': -19.3086, 'region_id__5': '3', 'state_id__5': '1', 'name__5': 'Prata' ... 8900 parameters truncated ... 'name__994': 'Serra Azul', 'timezone_name__994': 'America/Sao_Paulo', 'is_capital__994': False, 'longitude__994': -47.5602, 'ddd__994': '16', 'id__995': '66501', 'latitude__995': -18.3602, 'region_id__995': '3', 'state_id__995': '1', 'name__995': 'Serra Azul de Minas', 'timezone_name__995': 'America/Sao_Paulo', 'is_capital__995': False, 'longitude__995': -43.1675, 'ddd__995': '38', 'id__996': '15500', 'latitude__996': -7.48034, 'region_id__996': '2', 'state_id__996': '5', 'name__996': 'Serra Branca', 'timezone_name__996': 'America/Sao_Paulo', 'is_capital__996': False, 'longitude__996': -36.666, 'ddd__996': '83', 'id__997': '10306', 'latitude__997': -6.10478, 'region_id__997': '2', 'state_id__997': '4', 'name__997': 'Serra Caiada', 'timezone_name__997': 'America/Sao_Paulo', 'is_capital__997': False, 'longitude__997': -35.7113, 'ddd__997': '84', 'id__998': '15609', 'latitude__998': -6.68527, 'region_id__998': '2', 'state_id__998': '5', 'name__998': 'Serra da Raiz', 'timezone_name__998': 'America/Sao_Paulo', 'is_capital__998': False, 'longitude__998': -35.4379, 'ddd__998': '83', 'id__999': '66600', 'latitude__999': -19.4447, 'region_id__999': '3', 'state_id__999': '1', 'name__999': 'Serra da Saudade', 'timezone_name__999': 'America/Sao_Paulo', 'is_capital__999': False, 'longitude__999': -45.795, 'ddd__999': '37'}\n",
      "2025-09-20 16:00:10,618 INFO sqlalchemy.engine.Engine INSERT INTO cities (id, name, is_capital, longitude, latitude, ddd, timezone_name, region_id, state_id) VALUES (%(id__0)s, %(name__0)s, %(is_capital__0)s, %(longitude__0)s, %(latitude__0)s, %(ddd__0)s, %(timezone_name__0)s, %(region_id__0)s, %(state_ ... 93959 characters truncated ... 9)s, %(latitude__569)s, %(ddd__569)s, %(timezone_name__569)s, %(region_id__569)s, %(state_id__569)s)\n",
      "2025-09-20 16:00:10,619 INFO sqlalchemy.engine.Engine [insertmanyvalues 6/6 (unordered)] {'id__0': '13300', 'latitude__0': -6.41762, 'region_id__0': '2', 'state_id__0': '4', 'name__0': 'Serra de São Bento', 'timezone_name__0': 'America/Sao_Paulo', 'is_capital__0': False, 'longitude__0': -35.7033, 'ddd__0': '84', 'id__1': '13359', 'latitude__1': -5.17725, 'region_id__1': '2', 'state_id__1': '4', 'name__1': 'Serra do Mel', 'timezone_name__1': 'America/Sao_Paulo', 'is_capital__1': False, 'longitude__1': -37.0242, 'ddd__1': '84', 'id__2': '00055', 'latitude__2': 0.901357, 'region_id__2': '1', 'state_id__2': '6', 'name__2': 'Serra do Navio', 'timezone_name__2': 'America/Sao_Paulo', 'is_capital__2': False, 'longitude__2': -52.0036, 'ddd__2': '96', 'id__3': '30154', 'latitude__3': -13.5659, 'region_id__3': '2', 'state_id__3': '9', 'name__3': 'Serra do Ramalho', 'timezone_name__3': 'America/Sao_Paulo', 'is_capital__3': False, 'longitude__3': -43.5929, 'ddd__3': '77', 'id__4': '66808', 'latitude__4': -19.1083, 'region_id__4': '3', 'state_id__4': '1', 'name__4': 'Serra do Salitre', 'timezone_name__4': 'America/Sao_Paulo', 'is_capital__4': False, 'longitude__4': -46.6961, 'ddd__4': '34', 'id__5': '66709', 'latitude__5': -17.7872, 'region_id__5': '3', 'state_id__5': '1', 'name__5': 'Serra dos Aimorés' ... 5030 parameters truncated ... 'name__564': 'Xinguara', 'timezone_name__564': 'America/Sao_Paulo', 'is_capital__564': False, 'longitude__564': -49.9437, 'ddd__564': '94', 'id__565': '33604', 'latitude__565': -10.823, 'region_id__565': '2', 'state_id__565': '9', 'name__565': 'Xique-Xique', 'timezone_name__565': 'America/Sao_Paulo', 'is_capital__565': False, 'longitude__565': -42.7245, 'ddd__565': '74', 'id__566': '17407', 'latitude__566': -8.07901, 'region_id__566': '2', 'state_id__566': '5', 'name__566': 'Zabelê', 'timezone_name__566': 'America/Sao_Paulo', 'is_capital__566': False, 'longitude__566': -37.1057, 'ddd__566': '83', 'id__567': '57154', 'latitude__567': -21.0506, 'region_id__567': '3', 'state_id__567': '5', 'name__567': 'Zacarias', 'timezone_name__567': 'America/Sao_Paulo', 'is_capital__567': False, 'longitude__567': -50.0552, 'ddd__567': '18', 'id__568': '14007', 'latitude__568': -3.27014, 'region_id__568': '2', 'state_id__568': '1', 'name__568': 'Zé Doca', 'timezone_name__568': 'America/Sao_Paulo', 'is_capital__568': False, 'longitude__568': -45.6553, 'ddd__568': '98', 'id__569': '19853', 'latitude__569': -27.4521, 'region_id__569': '4', 'state_id__569': '2', 'name__569': 'Zortéa', 'timezone_name__569': 'America/Sao_Paulo', 'is_capital__569': False, 'longitude__569': -51.552, 'ddd__569': '49'}\n",
      "2025-09-20 16:00:10,662 INFO sqlalchemy.engine.Engine COMMIT\n",
      "✅ Inserted 5570 base city records.\n",
      "\n",
      "Phase 2.1: Enriching with households data...\n",
      "2025-09-20 16:00:10,832 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:10,906 INFO sqlalchemy.engine.Engine UPDATE cities SET urban=%(urban)s, rural=%(rural)s WHERE cities.region_id = %(cities_region_id)s AND cities.state_id = %(cities_state_id)s AND cities.id = %(cities_id)s\n",
      "2025-09-20 16:00:10,907 INFO sqlalchemy.engine.Engine [generated in 0.02972s] [{'urban': 18450, 'rural': 678, 'cities_region_id': '5', 'cities_state_id': '2', 'cities_id': '00050'}, {'urban': 4392, 'rural': 1880, 'cities_region_id': '3', 'cities_state_id': '1', 'cities_id': '00104'}, {'urban': 13063, 'rural': 4169, 'cities_region_id': '5', 'cities_state_id': '2', 'cities_id': '00100'}, {'urban': 20260, 'rural': 2415, 'cities_region_id': '3', 'cities_state_id': '1', 'cities_id': '00203'}, {'urban': 98390, 'rural': 59798, 'cities_region_id': '1', 'cities_state_id': '5', 'cities_id': '00107'}, {'urban': 5572, 'rural': 4466, 'cities_region_id': '2', 'cities_state_id': '3', 'cities_id': '00101'}, {'urban': 3555, 'rural': 3746, 'cities_region_id': '2', 'cities_state_id': '9', 'cities_id': '00108'}, {'urban': 9858, 'rural': 7781, 'cities_region_id': '2', 'cities_state_id': '9', 'cities_id': '00207'}  ... displaying 10 of 5570 total bound parameter sets ...  {'urban': 27458, 'rural': 13343, 'cities_region_id': '2', 'cities_state_id': '1', 'cities_id': '14007'}, {'urban': 3500, 'rural': 430, 'cities_region_id': '4', 'cities_state_id': '2', 'cities_id': '19853'}]\n",
      "2025-09-20 16:00:12,208 INFO sqlalchemy.engine.Engine COMMIT\n",
      "✅ Updated 5570 records with household data.\n",
      "\n",
      "Phase 2.2: Enriching with population race data...\n",
      "2025-09-20 16:00:12,749 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:12,883 INFO sqlalchemy.engine.Engine UPDATE cities SET population_race=%(population_race)s::JSON WHERE cities.region_id = %(cities_region_id)s AND cities.state_id = %(cities_state_id)s AND cities.id = %(cities_id)s\n",
      "2025-09-20 16:00:12,884 INFO sqlalchemy.engine.Engine [generated in 0.08623s] [{'population_race': '{\"white\": {\"male\": 4940, \"female\": 2447}, \"black\": {\"male\": 2115, \"female\": 1137}, \"yellow\": {\"male\": 978, \"female\": 116}, \"pardo\": {\"male\": 46, \"female\": 70}, \"indigenous\": {\"male\": 11884, \"female\": 6053}}', 'cities_region_id': '5', 'cities_state_id': '2', 'cities_id': '00050'}, {'population_race': '{\"white\": {\"male\": 3620, \"female\": 1796}, \"black\": {\"male\": 248, \"female\": 122}, \"yellow\": {\"male\": 126, \"female\": 0}, \"pardo\": {\"male\": 0, \"female\": 0}, \"indigenous\": {\"male\": 2404, \"female\": 1243}}', 'cities_region_id': '3', 'cities_state_id': '1', 'cities_id': '00104'}, {'population_race': '{\"white\": {\"male\": 6339, \"female\": 3096}, \"black\": {\"male\": 931, \"female\": 551}, \"yellow\": {\"male\": 380, \"female\": 19}, \"pardo\": {\"male\": 11, \"female\": 8}, \"indigenous\": {\"male\": 9933, \"female\": 5146}}', 'cities_region_id': '5', 'cities_state_id': '2', 'cities_id': '00100'}, {'population_race': '{\"white\": {\"male\": 10286, \"female\": 5043}, \"black\": {\"male\": 1801, \"female\": 958}, \"yellow\": {\"male\": 843, \"female\": 10}, \"pardo\": {\"male\": 6, \"female\": 4}, \"indigenous\": {\"male\": 10567, \"female\": 5188}}', 'cities_region_id': '3', 'cities_state_id': '1', 'cities_id': '00203'}, {'population_race': '{\"white\": {\"male\": 29624, \"female\": 14201}, \"black\": {\"male\": 15895, \"female\": 8579}, \"yellow\": {\"male\": 7316, \"female\": 107}, \"pardo\": {\"male\": 44, \"female\": 63}, \"indigenous\": {\"male\": 112187, \"female\": 56147}}', 'cities_region_id': '1', 'cities_state_id': '5', 'cities_id': '00107'}, {'population_race': '{\"white\": {\"male\": 2357, \"female\": 1164}, \"black\": {\"male\": 745, \"female\": 392}, \"yellow\": {\"male\": 353, \"female\": 11}, \"pardo\": {\"male\": 3, \"female\": 8}, \"indigenous\": {\"male\": 6920, \"female\": 3369}}', 'cities_region_id': '2', 'cities_state_id': '3', 'cities_id': '00101'}, {'population_race': '{\"white\": {\"male\": 2974, \"female\": 1430}, \"black\": {\"male\": 572, \"female\": 298}, \"yellow\": {\"male\": 274, \"female\": 5}, \"pardo\": {\"male\": 2, \"female\": 3}, \"indigenous\": {\"male\": 3742, \"female\": 1831}}', 'cities_region_id': '2', 'cities_state_id': '9', 'cities_id': '00108'}, {'population_race': '{\"white\": {\"male\": 2054, \"female\": 1004}, \"black\": {\"male\": 2527, \"female\": 1310}, \"yellow\": {\"male\": 1217, \"female\": 16}, \"pardo\": {\"male\": 8, \"female\": 8}, \"indigenous\": {\"male\": 10666, \"female\": 5197}}', 'cities_region_id': '2', 'cities_state_id': '9', 'cities_id': '00207'}  ... displaying 10 of 5570 total bound parameter sets ...  {'population_race': '{\"white\": {\"male\": 6875, \"female\": 3338}, \"black\": {\"male\": 3722, \"female\": 1973}, \"yellow\": {\"male\": 1749, \"female\": 9}, \"pardo\": {\"male\": 3, \"female\": 6}, \"indigenous\": {\"male\": 29787, \"female\": 14606}}', 'cities_region_id': '2', 'cities_state_id': '1', 'cities_id': '14007'}, {'population_race': '{\"white\": {\"male\": 2739, \"female\": 1357}, \"black\": {\"male\": 188, \"female\": 105}, \"yellow\": {\"male\": 83, \"female\": 1}, \"pardo\": {\"male\": 0, \"female\": 1}, \"indigenous\": {\"male\": 1002, \"female\": 543}}', 'cities_region_id': '4', 'cities_state_id': '2', 'cities_id': '19853'}]\n",
      "2025-09-20 16:00:14,191 INFO sqlalchemy.engine.Engine COMMIT\n",
      "✅ Updated 5570 records with race data.\n",
      "\n",
      "Phase 2.3: Enriching with population education data...\n",
      "2025-09-20 16:00:14,778 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:00:15,019 INFO sqlalchemy.engine.Engine UPDATE cities SET population_education=%(population_education)s::JSON WHERE cities.region_id = %(cities_region_id)s AND cities.state_id = %(cities_state_id)s AND cities.id = %(cities_id)s\n",
      "2025-09-20 16:00:15,020 INFO sqlalchemy.engine.Engine [generated in 0.20115s] [{'population_education': '{\"education\": {\"male\": 30, \"female\": 268}, \"arts_and_humanities\": {\"male\": 21, \"female\": 29}, \"social_sciences\": {\"male\": 4, \"female\": 30}, \"administ ... (192 characters truncated) ... re\": {\"male\": 17, \"female\": 25}, \"health\": {\"male\": 43, \"female\": 168}, \"services\": {\"male\": 10, \"female\": 11}, \"unknown\": {\"male\": 6, \"female\": 26}}', 'cities_region_id': '5', 'cities_state_id': '2', 'cities_id': '00050'}, {'population_education': '{\"education\": {\"male\": 6, \"female\": 84}, \"arts_and_humanities\": {\"male\": 31, \"female\": 45}, \"social_sciences\": {\"male\": 15, \"female\": 17}, \"administr ... (186 characters truncated) ... ture\": {\"male\": 28, \"female\": 19}, \"health\": {\"male\": 28, \"female\": 68}, \"services\": {\"male\": 0, \"female\": 3}, \"unknown\": {\"male\": 14, \"female\": 18}}', 'cities_region_id': '3', 'cities_state_id': '1', 'cities_id': '00104'}, {'population_education': '{\"education\": {\"male\": 18, \"female\": 228}, \"arts_and_humanities\": {\"male\": 29, \"female\": 41}, \"social_sciences\": {\"male\": 9, \"female\": 0}, \"administr ... (188 characters truncated) ... ure\": {\"male\": 0, \"female\": 0}, \"health\": {\"male\": 67, \"female\": 128}, \"services\": {\"male\": 22, \"female\": 19}, \"unknown\": {\"male\": 10, \"female\": 30}}', 'cities_region_id': '5', 'cities_state_id': '2', 'cities_id': '00100'}, {'population_education': '{\"education\": {\"male\": 10, \"female\": 331}, \"arts_and_humanities\": {\"male\": 39, \"female\": 124}, \"social_sciences\": {\"male\": 10, \"female\": 80}, \"admini ... (196 characters truncated) ... e\": {\"male\": 107, \"female\": 27}, \"health\": {\"male\": 130, \"female\": 292}, \"services\": {\"male\": 0, \"female\": 20}, \"unknown\": {\"male\": 9, \"female\": 78}}', 'cities_region_id': '3', 'cities_state_id': '1', 'cities_id': '00203'}, {'population_education': '{\"education\": {\"male\": 657, \"female\": 2537}, \"arts_and_humanities\": {\"male\": 455, \"female\": 1126}, \"social_sciences\": {\"male\": 270, \"female\": 312}, \" ... (210 characters truncated) ... {\"male\": 27, \"female\": 79}, \"health\": {\"male\": 712, \"female\": 1131}, \"services\": {\"male\": 11, \"female\": 20}, \"unknown\": {\"male\": 117, \"female\": 124}}', 'cities_region_id': '1', 'cities_state_id': '5', 'cities_id': '00107'}, {'population_education': '{\"education\": {\"male\": 37, \"female\": 182}, \"arts_and_humanities\": {\"male\": 11, \"female\": 112}, \"social_sciences\": {\"male\": 0, \"female\": 21}, \"adminis ... (181 characters truncated) ... culture\": {\"male\": 0, \"female\": 0}, \"health\": {\"male\": 18, \"female\": 55}, \"services\": {\"male\": 0, \"female\": 0}, \"unknown\": {\"male\": 0, \"female\": 23}}', 'cities_region_id': '2', 'cities_state_id': '3', 'cities_id': '00101'}, {'population_education': '{\"education\": {\"male\": 21, \"female\": 120}, \"arts_and_humanities\": {\"male\": 18, \"female\": 24}, \"social_sciences\": {\"male\": 6, \"female\": 8}, \"administr ... (180 characters truncated) ... culture\": {\"male\": 0, \"female\": 4}, \"health\": {\"male\": 17, \"female\": 46}, \"services\": {\"male\": 0, \"female\": 0}, \"unknown\": {\"male\": 8, \"female\": 23}}', 'cities_region_id': '2', 'cities_state_id': '9', 'cities_id': '00108'}, {'population_education': '{\"education\": {\"male\": 25, \"female\": 131}, \"arts_and_humanities\": {\"male\": 11, \"female\": 123}, \"social_sciences\": {\"male\": 12, \"female\": 88}, \"admini ... (185 characters truncated) ... culture\": {\"male\": 3, \"female\": 17}, \"health\": {\"male\": 12, \"female\": 95}, \"services\": {\"male\": 0, \"female\": 0}, \"unknown\": {\"male\": 0, \"female\": 8}}', 'cities_region_id': '2', 'cities_state_id': '9', 'cities_id': '00207'}  ... displaying 10 of 5570 total bound parameter sets ...  {'population_education': '{\"education\": {\"male\": 136, \"female\": 465}, \"arts_and_humanities\": {\"male\": 69, \"female\": 218}, \"social_sciences\": {\"male\": 10, \"female\": 17}, \"admin ... (194 characters truncated) ... re\": {\"male\": 27, \"female\": 37}, \"health\": {\"male\": 63, \"female\": 143}, \"services\": {\"male\": 7, \"female\": 10}, \"unknown\": {\"male\": 13, \"female\": 84}}', 'cities_region_id': '2', 'cities_state_id': '1', 'cities_id': '14007'}, {'population_education': '{\"education\": {\"male\": 0, \"female\": 76}, \"arts_and_humanities\": {\"male\": 3, \"female\": 12}, \"social_sciences\": {\"male\": 0, \"female\": 3}, \"administrati ... (177 characters truncated) ... culture\": {\"male\": 9, \"female\": 3}, \"health\": {\"male\": 12, \"female\": 10}, \"services\": {\"male\": 6, \"female\": 0}, \"unknown\": {\"male\": 3, \"female\": 32}}', 'cities_region_id': '4', 'cities_state_id': '2', 'cities_id': '19853'}]\n",
      "2025-09-20 16:00:16,587 INFO sqlalchemy.engine.Engine COMMIT\n",
      "✅ Updated 5570 records with education data.\n",
      "\n",
      "🎉 All city data loaded and merged successfully!\n"
     ]
    }
   ],
   "source": [
    "def generate_city_uf_key(name: str, uf: str) -> str:\n",
    "    \"\"\"Creates a standardized, URL-friendly key from a city name and UF.\"\"\"\n",
    "    # Normalize (remove accents), convert to lowercase, replace spaces with hyphens\n",
    "    normalized_name = ''.join(c for c in unicodedata.normalize('NFD', name) \n",
    "                              if unicodedata.category(c) != 'Mn')\n",
    "    return f\"{normalized_name.lower().replace(' ', '-')}_{uf.lower()}\"\n",
    "\n",
    "def parse_municipio(municipio_str: str) -> tuple[str, str] | None:\n",
    "    \"\"\"Parses a string like 'São Carlos (SP)' into ('São Carlos', 'SP').\"\"\"\n",
    "    match = re.match(r'^(.*?)\\s*\\((.*?)\\)$', municipio_str)\n",
    "    if match:\n",
    "        return match.group(1).strip(), match.group(2).strip()\n",
    "    return None\n",
    "\n",
    "def create_race_json(row: pd.Series) -> dict:\n",
    "    \"\"\"Builds the population_race JSON object from a DataFrame row.\"\"\"\n",
    "    return {\n",
    "        'white': {'male': row[4], 'female': row[5]},\n",
    "        'black': {'male': row[7], 'female': row[8]},\n",
    "        'yellow': {'male': row[9], 'female': row[10]},\n",
    "        'pardo': {'male': row[11], 'female': row[12]},\n",
    "        'indigenous': {'male': row[13], 'female': row[14]},\n",
    "    }\n",
    "\n",
    "def create_education_json(row: pd.Series) -> dict:\n",
    "    \"\"\"Builds the population_education JSON object from a DataFrame row.\"\"\"\n",
    "    return {\n",
    "        'education': {'male': row[3], 'female': row[4]},\n",
    "        'arts_and_humanities': {'male': row[5], 'female': row[6]},\n",
    "        'social_sciences': {'male': row[7], 'female': row[8]},\n",
    "        'administration': {'male': row[9], 'female': row[10]},\n",
    "        'natural_sciences': {'male': row[11], 'female': row[12]},\n",
    "        'information_tecnology': {'male': row[13], 'female': row[14]},\n",
    "        'engineering': {'male': row[15], 'female': row[16]},\n",
    "        'agriculture': {'male': row[17], 'female': row[18]},\n",
    "        'health': {'male': row[19], 'female': row[20]},\n",
    "        'services': {'male': row[21], 'female': row[22]},\n",
    "        'unknown': {'male': row[23], 'female': row[24]},\n",
    "    }\n",
    "\n",
    "with Session() as session:\n",
    "    # Query for the necessary columns from the State table\n",
    "    stmt = select(State.region_id, State.id, State.uf)\n",
    "    results = session.execute(stmt).all()\n",
    "    \n",
    "    # Construct the dictionary by combining region_id and id for the key\n",
    "    state_map = {res.region_id + res.id: res.uf for res in results}\n",
    "\n",
    "    # === PHASE 1: INITIAL LOAD FROM MAIN CSV ===\n",
    "    print(\"Phase 1: Loading initial city data...\")\n",
    "    df_cities = pd.read_csv(**FILES['cities'])\n",
    "    df_cities.fillna({'ddd': 0}, inplace=True) # Handle potential NaN in ddd\n",
    "\n",
    "    cities_to_insert = []\n",
    "    for _, row in df_cities.iterrows():\n",
    "        ibge_code = str(row['codigo_ibge'])\n",
    "        state_code = ibge_code[:2]\n",
    "        \n",
    "        # Create the city_uf_key for future merges\n",
    "        uf = state_map.get(state_code)\n",
    "        \n",
    "        city_data = {\n",
    "            'region_id': ibge_code[0],\n",
    "            'state_id': ibge_code[1],\n",
    "            'id': ibge_code[2:],\n",
    "            'name': row['nome'],\n",
    "            'latitude': row['latitude'],\n",
    "            'longitude': row['longitude'],\n",
    "            'ddd': str(int(row['ddd'])),\n",
    "            'is_capital': bool(row['capital']),\n",
    "            'timezone_name': row['fuso_horario'],\n",
    "            # Add city_uf_key temporarily for in-memory joins\n",
    "            '_city_uf_key': generate_city_uf_key(row['nome'], uf)\n",
    "        }\n",
    "        cities_to_insert.append(city_data)\n",
    "\n",
    "    # Perform the initial bulk insert\n",
    "    session.bulk_insert_mappings(City, cities_to_insert)\n",
    "    session.commit()\n",
    "    print(f\"✅ Inserted {len(cities_to_insert)} base city records.\")\n",
    "\n",
    "    # Create a DataFrame from the inserted data for easy merging\n",
    "    df_inserted = pd.DataFrame(cities_to_insert)\n",
    "\n",
    "    # === PHASE 2: ENRICHMENT ===\n",
    "    \n",
    "    # --- Households Data ---\n",
    "    print(\"\\nPhase 2.1: Enriching with households data...\")\n",
    "    df_house = pd.read_csv(**FILES['households'])\n",
    "    df_house.dropna(subset=['Município'], inplace=True)\n",
    "    \n",
    "    # Create the merge key\n",
    "    parsed_data = df_house['Município'].apply(parse_municipio)\n",
    "    df_house[['name', 'uf']] = pd.DataFrame(parsed_data.tolist(), index=df_house.index)\n",
    "    df_house['_city_uf_key'] = df_house.apply(lambda row: generate_city_uf_key(row['name'], row['uf']), axis=1)\n",
    "\n",
    "    # Merge to get the primary keys\n",
    "    df_merged_house = pd.merge(df_inserted, df_house, on='_city_uf_key')\n",
    "    \n",
    "    households_to_update = df_merged_house[[\n",
    "        'region_id', 'state_id', 'id', 'Urbana', 'Rural'\n",
    "    ]].rename(columns={'Urbana': 'urban', 'Rural': 'rural'}).to_dict('records')\n",
    "\n",
    "    session.bulk_update_mappings(City, households_to_update)\n",
    "    session.commit()\n",
    "    print(f\"✅ Updated {len(households_to_update)} records with household data.\")\n",
    "\n",
    "    # --- Race Data ---\n",
    "    print(\"\\nPhase 2.2: Enriching with population race data...\")\n",
    "    df_race = pd.read_csv(**FILES['race'])\n",
    "    df_race.dropna(subset=[0], inplace=True)\n",
    "\n",
    "    parsed_data_race = df_race[0].apply(parse_municipio)\n",
    "    df_race[['name', 'uf']] = pd.DataFrame(parsed_data_race.tolist(), index=df_race.index)\n",
    "    df_race['_city_uf_key'] = df_race.apply(lambda row: generate_city_uf_key(row['name'], row['uf']), axis=1)\n",
    "    df_race['population_race'] = df_race.apply(create_race_json, axis=1)\n",
    "\n",
    "    df_merged_race = pd.merge(df_inserted, df_race, on='_city_uf_key')\n",
    "\n",
    "    race_to_update = df_merged_race[[\n",
    "        'region_id', 'state_id', 'id', 'population_race'\n",
    "    ]].to_dict('records')\n",
    "\n",
    "    session.bulk_update_mappings(City, race_to_update)\n",
    "    session.commit()\n",
    "    print(f\"✅ Updated {len(race_to_update)} records with race data.\")\n",
    "    \n",
    "    # --- Education Data ---\n",
    "    print(\"\\nPhase 2.3: Enriching with population education data...\")\n",
    "    df_edu = pd.read_csv(**FILES['education'])\n",
    "    df_edu.dropna(subset=[0], inplace=True)\n",
    "\n",
    "    parsed_data_edu = df_edu[0].apply(parse_municipio)\n",
    "    df_edu[['name', 'uf']] = pd.DataFrame(parsed_data_edu.tolist(), index=df_edu.index)\n",
    "    df_edu['_city_uf_key'] = df_edu.apply(lambda row: generate_city_uf_key(row['name'], row['uf']), axis=1)\n",
    "    df_edu['population_education'] = df_edu.apply(create_education_json, axis=1)\n",
    "\n",
    "    df_merged_edu = pd.merge(df_inserted, df_edu, on='_city_uf_key')\n",
    "\n",
    "    edu_to_update = df_merged_edu[[\n",
    "        'region_id', 'state_id', 'id', 'population_education'\n",
    "    ]].to_dict('records')\n",
    "\n",
    "    session.bulk_update_mappings(City, edu_to_update)\n",
    "    session.commit()\n",
    "    print(f\"✅ Updated {len(edu_to_update)} records with education data.\")\n",
    "    \n",
    "    print(\"\\n🎉 All city data loaded and merged successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe0e3ca1-0360-4df1-b92b-cde0bd449e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearby_cities(\n",
    "    session: Session,\n",
    "    city_name: str,\n",
    "    uf_code: str,\n",
    "    count: int,\n",
    "    distance_metric: str\n",
    ") -> list[City] | None:\n",
    "    \"\"\"\n",
    "    Finds a specified number of cities closest to a target city.\n",
    "\n",
    "    Args:\n",
    "        session: The SQLAlchemy session for database queries.\n",
    "        city_name: The name of the target city (e.g., 'São Carlos').\n",
    "        uf_code: The two-letter state code of the target city (e.g., 'SP').\n",
    "        count: The number of nearby cities to return.\n",
    "        distance_metric: The distance metric ('manhattan' or 'euclidean').\n",
    "\n",
    "    Returns:\n",
    "        A list of City ORM objects, or None if the target city is not found.\n",
    "    \"\"\"\n",
    "    # Step 1: Find the target city's coordinates and IBGE code\n",
    "    print(f\"Finding coordinates for {city_name}, {uf_code}...\")\n",
    "    stmt = select(City.location).join_from(City, State).where(\n",
    "        City.name == city_name,\n",
    "        State.uf == uf_code\n",
    "    )\n",
    "    target = session.execute(stmt).first()\n",
    "    \n",
    "    if not target:\n",
    "        print(f\"Error: {city_name}, {uf_code} not found in the database.\")\n",
    "        return None\n",
    "        \n",
    "    target_lon = target.location.longitude\n",
    "    target_lat = target.location.latitude\n",
    "    print(f\"Found {city_name} at ({target_lat:.4f}, {target_lon:.4f})\")\n",
    "\n",
    "    # Step 2: Query for the closest cities\n",
    "    print(f\"Querying for the top {count + 1} closest cities using {distance_metric} distance...\")\n",
    "    \n",
    "    # CORRECTED: Call the hybrid method on the City.location attribute\n",
    "    distance_expr = City.location.distance(\n",
    "        target_lon, target_lat, metric=distance_metric\n",
    "    ).label(\"distance\")\n",
    "    \n",
    "    stmt = select(City).order_by(distance_expr).limit(count + 1)\n",
    "    \n",
    "    all_results = session.execute(stmt).scalars().all()\n",
    "    closest_cities = all_results[1:]\n",
    "    \n",
    "    print(f\"Found {len(closest_cities)} nearby cities:\")\n",
    "    for city in closest_cities:\n",
    "        # Assuming the 'state' relationship is available for eager/lazy loading\n",
    "        print(f\"- {city.name}, {city.state.uf}\")\n",
    "        \n",
    "    return closest_cities\n",
    "\n",
    "def plot_demographic_distributions(\n",
    "    cities: list[City],\n",
    "    language: str = 'en'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Processes and plots demographic data from a list of City objects, with\n",
    "    support for English ('en') and Portuguese ('pt') languages.\n",
    "    \"\"\"\n",
    "    if not cities:\n",
    "        print(\"No cities provided to plot. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # --- Translation Dictionary ---\n",
    "    TRANSLATIONS = {\n",
    "        'pt': {\n",
    "            'male': 'Homens', 'female': 'Mulheres', 'gender': 'Gênero',\n",
    "            'race_cats': {\n",
    "                'White': 'Branca', 'Black': 'Preta', 'Yellow': 'Amarela',\n",
    "                'Pardo': 'Parda', 'Indigenous': 'Indígena'\n",
    "            },\n",
    "            'edu_cats': {\n",
    "                'Education': 'Educação', 'Arts And Humanities': 'Artes e Humanidades',\n",
    "                'Social Sciences': 'Ciências Sociais', 'Administration': 'Administração',\n",
    "                'Natural Sciences': 'Ciências Naturais', 'Information Tecnology': 'Tecnologia da Informação',\n",
    "                'Engineering': 'Engenharia', 'Agriculture': 'Agricultura',\n",
    "                'Health': 'Saúde', 'Services': 'Serviços', 'Unknown': 'Não especificado'\n",
    "            },\n",
    "            'plot1_title': 'População por Raça e Gênero ({count} Cidades Próximas)',\n",
    "            'plot1_xlabel': 'Categoria de Raça',\n",
    "            'plot2_title': 'População por Área de Formação e Gênero ({count} Cidades Próximas)',\n",
    "            'plot2_xlabel': 'Área de Formação',\n",
    "            'plot3_title': 'Distribuição Total de Homens vs. Mulheres ({count} Cidades Próximas)',\n",
    "            'total_pop': 'População Total', 'group': 'Grupo',\n",
    "            'group_race': 'Raça', 'group_edu': 'Formação'\n",
    "        }\n",
    "    }\n",
    "    # Fallback to English if language is not 'pt'\n",
    "    lang_map = TRANSLATIONS.get(language, {})\n",
    "\n",
    "    # --- Data Processing ---\n",
    "    race_data = []\n",
    "    edu_data = []\n",
    "    for city in cities:\n",
    "        for cat, genders in city.population_race.items():\n",
    "            en_cat = cat.replace('_', ' ').title()\n",
    "            race_data.append({\n",
    "                \"race\": lang_map.get('race_cats', {}).get(en_cat, en_cat),\n",
    "                \"male\": genders.get('male', 0),\n",
    "                \"female\": genders.get('female', 0)\n",
    "            })\n",
    "        for cat, genders in city.population_education.items():\n",
    "            en_cat = cat.replace('_', ' ').title()\n",
    "            edu_data.append({\n",
    "                \"education_field\": lang_map.get('edu_cats', {}).get(en_cat, en_cat),\n",
    "                \"male\": genders.get('male', 0),\n",
    "                \"female\": genders.get('female', 0)\n",
    "            })\n",
    "\n",
    "    df_race = pd.DataFrame(race_data)\n",
    "    df_edu = pd.DataFrame(edu_data)\n",
    "    race_summary = df_race.groupby('race')[['male', 'female']].sum()\n",
    "    edu_summary = df_edu.groupby('education_field')[['male', 'female']].sum()\n",
    "    \n",
    "    # Rename columns for legend translation\n",
    "    if language == 'pt':\n",
    "        race_summary.rename(columns={'male': lang_map['male'], 'female': lang_map['female']}, inplace=True)\n",
    "        edu_summary.rename(columns={'male': lang_map['male'], 'female': lang_map['female']}, inplace=True)\n",
    "\n",
    "    # --- Plot Generation ---\n",
    "    print(\"Gerando gráficos demográficos...\")\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 22))\n",
    "    \n",
    "    # Plot 1: Race\n",
    "    race_summary.plot(kind='bar', stacked=True, ax=axes[0], colormap='viridis')\n",
    "    axes[0].set_title(lang_map.get('plot1_title', 'Pop. by Race').format(count=len(cities)), fontsize=16)\n",
    "    axes[0].set_xlabel(lang_map.get('plot1_xlabel', 'Race Category'), fontsize=12)\n",
    "    axes[0].set_ylabel(lang_map.get('total_pop', 'Total Population'), fontsize=12)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Education\n",
    "    edu_summary.plot(kind='bar', stacked=True, ax=axes[1], colormap='plasma')\n",
    "    axes[1].set_title(lang_map.get('plot2_title', 'Pop. by Education').format(count=len(cities)), fontsize=16)\n",
    "    axes[1].set_xlabel(lang_map.get('plot2_xlabel', 'Education Field'), fontsize=12)\n",
    "    axes[1].set_ylabel(lang_map.get('total_pop', 'Total Population'), fontsize=12)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 3: Totals\n",
    "    df_totals = pd.DataFrame({\n",
    "        lang_map.get('group', 'Group'): [lang_map.get('group_race', 'Race')] * 2 + [lang_map.get('group_edu', 'Education')] * 2,\n",
    "        lang_map.get('gender', 'Gender'): [lang_map.get('male', 'Male'), lang_map.get('female', 'Female')] * 2,\n",
    "        lang_map.get('total_pop', 'Total Population'): [df_race['male'].sum(), df_race['female'].sum(), df_edu['male'].sum(), df_edu['female'].sum()]\n",
    "    })\n",
    "    sns.barplot(data=df_totals, x=lang_map.get('group', 'Group'), y=lang_map.get('total_pop', 'Total Population'), \n",
    "                hue=lang_map.get('gender', 'Gender'), ax=axes[2], palette='muted')\n",
    "    axes[2].set_title(lang_map.get('plot3_title', 'Total Gender Dist.').format(count=len(cities)), fontsize=16)\n",
    "    axes[2].set_xlabel('')\n",
    "    axes[2].set_ylabel(lang_map.get('total_pop', 'Total Population'), fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "754ae5eb-e6f2-4338-b03e-a80c1f97ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding coordinates for São Carlos, SP...\n",
      "2025-09-20 16:08:58,120 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-20 16:08:58,128 INFO sqlalchemy.engine.Engine SELECT cities.longitude, cities.latitude \n",
      "FROM cities JOIN states ON states.region_id = cities.region_id AND states.id = cities.state_id \n",
      "WHERE cities.name = %(name_1)s AND states.uf = %(uf_1)s\n",
      "2025-09-20 16:08:58,129 INFO sqlalchemy.engine.Engine [cached since 464.6s ago] {'name_1': 'São Carlos', 'uf_1': 'SP'}\n",
      "Found São Carlos at (-22.0174, -47.8860)\n",
      "Querying for the top 11 closest cities using manhattan distance...\n",
      "2025-09-20 16:08:58,133 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Neither 'property' object nor 'Comparator' object associated with City.location has an attribute 'distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/v5s2p5acimzx3109b1h5irz38bxghrnv-python3-3.12.11-env/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:720\u001b[39m, in \u001b[36mcreate_proxied_attribute.<locals>.Proxy.__getattr__\u001b[39m\u001b[34m(self, attribute)\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mAttributeError\u001b[39m: 'property' object has no attribute 'distance'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/v5s2p5acimzx3109b1h5irz38bxghrnv-python3-3.12.11-env/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:735\u001b[39m, in \u001b[36mcreate_proxied_attribute.<locals>.Proxy.__getattr__\u001b[39m\u001b[34m(self, attribute)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err3:\n",
      "\u001b[31mAttributeError\u001b[39m: 'Comparator' object has no attribute 'distance'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     cities = \u001b[43mfind_nearby_cities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSão Carlos\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSP\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmanhattan\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     plot_demographic_distributions(cities, \u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mfind_nearby_cities\u001b[39m\u001b[34m(session, city_name, uf_code, count, distance_metric)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuerying for the top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m closest cities using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m distance...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# CORRECTED: Call the hybrid method on the City.location attribute\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m distance_expr = \u001b[43mCity\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistance\u001b[49m(\n\u001b[32m     42\u001b[39m     target_lon, target_lat, metric=distance_metric\n\u001b[32m     43\u001b[39m ).label(\u001b[33m\"\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m stmt = select(City).order_by(distance_expr).limit(count + \u001b[32m1\u001b[39m)\n\u001b[32m     47\u001b[39m all_results = session.execute(stmt).scalars().all()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/v5s2p5acimzx3109b1h5irz38bxghrnv-python3-3.12.11-env/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:737\u001b[39m, in \u001b[36mcreate_proxied_attribute.<locals>.Proxy.__getattr__\u001b[39m\u001b[34m(self, attribute)\u001b[39m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(comparator, attribute)\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err3:\n\u001b[32m--> \u001b[39m\u001b[32m737\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    738\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNeither \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m object nor \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m object \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    739\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33massociated with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m has an attribute \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    740\u001b[39m         % (\n\u001b[32m    741\u001b[39m             \u001b[38;5;28mtype\u001b[39m(descriptor).\u001b[34m__name__\u001b[39m,\n\u001b[32m    742\u001b[39m             \u001b[38;5;28mtype\u001b[39m(comparator).\u001b[34m__name__\u001b[39m,\n\u001b[32m    743\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    744\u001b[39m             attribute,\n\u001b[32m    745\u001b[39m         )\n\u001b[32m    746\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr3\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: Neither 'property' object nor 'Comparator' object associated with City.location has an attribute 'distance'"
     ]
    }
   ],
   "source": [
    "with Session() as session:\n",
    "    cities = find_nearby_cities(session, 'São Carlos', 'SP', 10, 'manhattan')\n",
    "    plot_demographic_distributions(cities, 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac58e7a-86c3-4fa4-a387-ca92b9b7748b",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
