{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87afd18e-e584-4013-82ed-a1a4b634d313",
   "metadata": {},
   "source": [
    "# Geração de Databases com SQLalchemy e PosgreSQL\n",
    "\n",
    "O presente notebook demonstra a construção de bancos de dados (BD) SQL locais a partir do uso das ferramentas SQLalchemy e PostgreSQL, para fins de realização de uma análise exploratória de dados descritos em arquivos CSV. Para tal, fizemos uso do dataset [Covid-19 Data Sharing](https://agencia.fapesp.br/covid-19-data-sharingbr-makes-more-datasets-available/35348) disponibilizado pela Agência FAPESP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9b06c-e869-4be2-8bf0-fe102f2229b4",
   "metadata": {},
   "source": [
    "## Autores\n",
    "\n",
    "| Nome | nUSP |\n",
    "| :--- | :--- |\n",
    "| Guilherme de Abreu Barreto | 12543033 |\n",
    "| Lucas Eduardo Gulka Pulcinelli | 12547336 |\n",
    "| Vinicio Yusuke Hayashibara | 13642797 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41057348-ac0e-4d5b-81cc-62dd8887391c",
   "metadata": {},
   "source": [
    "## Configuração\n",
    "\n",
    "É necessário o ao correto funcionamento deste projeto possuir uma instalação local de PostgreSQL e atribuir os valores correspondentes para acesso a este nas seguintes constantes:\n",
    "\n",
    "- `DATABASE`: O nome do database onde serão carregadas as informações. Atente-se se este não corresponde ao nome de um database preexistente **ou que esteja sendo acessado**, pois este será então sobrescrito.\n",
    "\n",
    "- `USER` e `PASSWORD`: Informações de autententicação válidas e com privilégios para a criação de bancos de dados no servidor.\n",
    "\n",
    "- `HOST` e `PORT`: A URL e porta para realização do acesso ao servidor.\n",
    "\n",
    "- `BATCH_SIZE`: O número máximo de operações sobre o BD a serem realizadas conjuntamente. Recomenda-se ser em um número o qual caiba na memória RAM que você dispõe. O número abaixo foi capaz de caber confortávelmente em 10 GiB de RAM **na minha máquina**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8964e1-6dc4-4ef8-8a8d-b26eb450dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = \"postgres\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"postgres\"\n",
    "HOST = \"postgres\"\n",
    "PORT = 5432\n",
    "BATCH_SIZE = 2 * 10**6\n",
    "\n",
    "DATABASE_URI = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}/{DATABASE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ab4f1-0fde-4be4-8f4f-10d6cf9589cb",
   "metadata": {},
   "source": [
    "## Carregamento das dependências deste projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167791eb-294d-4435-b245-53ee89d7ba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.13/site-packages (4.67.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: sqlalchemy[postgres] in /opt/conda/lib/python3.13/site-packages (2.0.43)\n",
      "\u001b[33mWARNING: sqlalchemy 2.0.43 does not provide the extra 'postgres'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.13/site-packages (from sqlalchemy[postgres]) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.13/site-packages (from sqlalchemy[postgres]) (4.15.0)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading psycopg2_binary-2.9.10-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, psycopg2-binary, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.3 pandas-2.3.2 psycopg2-binary-2.9.10 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary sqlalchemy[postgres] tqdm pandas\n",
    "\n",
    "import enum\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from psycopg2.errors import UniqueViolation\n",
    "from sqlalchemy import (\n",
    "    CheckConstraint as constraint,\n",
    "    Enum,\n",
    "    Date,\n",
    "    ForeignKey as fk,\n",
    "    String,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    TypeDecorator,\n",
    "    create_engine,\n",
    "    column as sql_column,\n",
    "    insert,\n",
    "    text,\n",
    "    PrimaryKeyConstraint as pkc\n",
    ")\n",
    "from sqlalchemy.orm import (\n",
    "    Mapped,\n",
    "    Session,\n",
    "    declarative_base,\n",
    "    relationship,\n",
    "    sessionmaker,\n",
    "    mapped_column as column,\n",
    "    validates,\n",
    ")\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Annotated, final\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a5f36-93f6-40e9-8e22-578cad919506",
   "metadata": {},
   "source": [
    "## Funções e tipos de dados auxiliares\n",
    "\n",
    "Algumas funções e tipos de dados os quais utilizamos em nossa implementação, mas cuja funcionalidade provavelmente não será crucial ao caso geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc12eb0-a5bf-44be-af91-cf6519e1e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backref(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(back_populates=back_populates)\n",
    "\n",
    "\n",
    "def childOf(back_populates: str) -> Mapped[Any]:\n",
    "    return relationship(\n",
    "        back_populates=back_populates,\n",
    "        cascade=\"all, delete-orphan\",\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_column_name(column_name: str) -> str:\n",
    "    return column_name.lower()\n",
    "\n",
    "def parse_line(v):\n",
    "    try:\n",
    "        return parse(v)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_date(date_column: pd.Series) -> pd.Series:\n",
    "    return  date_column.apply(parse_line)\n",
    "\n",
    "\n",
    "estados = [\n",
    "    \"AC\",  # Acre\n",
    "    \"AL\",  # Alagoas\n",
    "    \"AP\",  # Amapá\n",
    "    \"AM\",  # Amazonas\n",
    "    \"BA\",  # Bahia\n",
    "    \"CE\",  # Ceará\n",
    "    \"DF\",  # Distrito Federal\n",
    "    \"ES\",  # Espírito Santo\n",
    "    \"GO\",  # Goiás\n",
    "    \"MA\",  # Maranhão\n",
    "    \"MT\",  # Mato Grosso\n",
    "    \"MS\",  # Mato Grosso do Sul\n",
    "    \"MG\",  # Minas Gerais\n",
    "    \"PA\",  # Pará\n",
    "    \"PB\",  # Paraíba\n",
    "    \"PR\",  # Paraná\n",
    "    \"PE\",  # Pernambuco\n",
    "    \"PI\",  # Piauí\n",
    "    \"RJ\",  # Rio de Janeiro\n",
    "    \"RN\",  # Rio Grande do Norte\n",
    "    \"RS\",  # Rio Grande do Sul\n",
    "    \"RO\",  # Rondônia\n",
    "    \"RR\",  # Roraima\n",
    "    \"SC\",  # Santa Catarina\n",
    "    \"SP\",  # São Paulo\n",
    "    \"SE\",  # Sergipe\n",
    "    \"TO\",  # Tocantins\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cd4b3-b8dd-4afe-a96e-df842eecf19f",
   "metadata": {},
   "source": [
    "## Definição das tabelas comuns\n",
    "\n",
    "Abaixo descrevemos a estrutura pretendida às tabelas Pacientes, ExamLabs e Despachos, comuns a todos o BDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ea8aa3-8ca6-42af-b523-d5b2a7791ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class PacienteBase(Base):\n",
    "    __abstract__: bool = True\n",
    "\n",
    "    ic_sexo: Mapped[str] = column(\n",
    "        Enum('M', 'F', name='sexo_enum'),\n",
    "        comment=\"Sexo do Paciente. F - Feminino; M - Masculino\"\n",
    "    )\n",
    "    aa_nascimento: Mapped[str | None] = column(\n",
    "        String(4),\n",
    "        comment=\"Ano de nascimento do Paciente. 4 caracteres alfanuméricos. Os 4 dígitos do ano do nascimento; ou AAAA - para ano de nascimento igual ou anterior a 1930 (visando anonimização); YYYY - quaisquer outros anos, em caso de anonimização do ano\"\n",
    "    )\n",
    "    cd_pais: Mapped[str | None] = column(\n",
    "        String(2),\n",
    "        comment=\"Pais de residencia do Paciente. 2 caracteres alfanuméricos. BR ou XX (país estrangeiro)\"\n",
    "    )\n",
    "    cd_uf: Mapped[str | None] = column(\n",
    "        Enum(*estados, name='estado_enum'),\n",
    "        comment=\"Unidade da Federacao de residencia do Paciente. 2 caracteres alfanuméricos\"\n",
    "    )\n",
    "    cd_municipio: Mapped[str | None] = column(\n",
    "        comment=\"Municipio de residencia do Paciente. Alfanumérico.\"\n",
    "    )\n",
    "    cd_cepreduzido: Mapped[str | None] = column(comment=\"[Descrição não encontrada nos comentários]\")\n",
    "\n",
    "    @validates(\"aa_nascimento\")\n",
    "    def validates_nascimento(self, _key: str, value: str) -> str:\n",
    "        match value:\n",
    "            case \"AAAA\" | \"YYYY\":\n",
    "                return value\n",
    "            case year if len(year) == 4 and year.isdigit():\n",
    "                return year\n",
    "            case _:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid AA_Nascimento value: {value}. Must be 'AAAA', 'YYYY', or a 4-digit number\"\n",
    "                )\n",
    "\n",
    "\n",
    "class Paciente(PacienteBase):\n",
    "    \"\"\"\n",
    "    Tabela de pacientes Covid-19 FAPESP\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"pacientes\"\n",
    "\n",
    "    id_paciente: Mapped[str] = column(\n",
    "        primary_key=True,\n",
    "        comment=\"Identificação única do paciente (correlaciona com o ID_PACIENTE de todos os arquivos onde aparece). 32 caracteres alfanuméricos\"\n",
    "    )\n",
    "\n",
    "    # Relações\n",
    "    exames: Mapped[list[\"ExamLab\"]] = childOf(\"paciente\")\n",
    "    desfechos: Mapped[list[\"Desfecho\"]] = childOf(\"paciente\")\n",
    "\n",
    "\n",
    "\n",
    "class ExamLab(Base):\n",
    "    \"\"\"\n",
    "    Tabela de exames Covid-19 FAPESP\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"examlabs\"\n",
    "\n",
    "    id: Mapped[int] = column(autoincrement=True, primary_key=True)\n",
    "    id_paciente: Mapped[str] = column(\n",
    "        fk(\"pacientes.id_paciente\"),\n",
    "        comment=\"Identificação única do paciente (correlaciona com o ID_PACIENTE de todos os arquivos onde aparece). 32 caracteres alfanuméricos\"\n",
    "    )\n",
    "    id_atendimento: Mapped[str | None] = column(\n",
    "        comment=\"Identificação única do atendimento. Correlaciona com o ID_ATENDIMENTO de todas as tabelas onde aparece. 32 caracteres alfanuméricos\"\n",
    "    )\n",
    "    de_exame: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do exame realizado. Alfanumérico. Exemplo: HEMOGRAMA, sangue total / GLICOSE, plasma / SODIO, soro / POTASSIO, soro. Um exame é composto por 1 ou mais analitos.\"\n",
    "    )\n",
    "    de_resultado: Mapped[str | None] = column(\n",
    "        comment=\"Resultado do exame, associado ao DE_ANALITO. Alfanumérico. Se DE_ANALITO exige valor numérico, NNNN se inteiro ou NNNN,NNN se casas decimais; Se DE_ANALITO exige qualitativo, String com domínio restrito; Se DE_ANALITO por observação microscópica, String conteúdo livre. Exemplo de dominio restrito - Positivo, Detectado, Reagente, nâo reagente, etc. Exemplo de conteúdo livre - 'não foram observados caracteres tóxico-degenerativos nos neutrófilos, não foram observadas atipias linfocitárias'\"\n",
    "    )\n",
    "    dt_coleta: Mapped[date | None] = column(\n",
    "        comment=\"Data em que o material foi coletado do paciente\"\n",
    "    )\n",
    "    de_origem: Mapped[str | None] = column(\n",
    "        comment=\"Local de Coleta do exame. 4 caracteres alfabéticos: LAB – Exame realizado por paciente em uma unidade de atendimento laboratorial; HOSP – Exame realizado por paciente dentro de uma Unidade Hospitalar; UTI - exame realizado na UTI\"\n",
    "    )\n",
    "    de_analito: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do analito. Alfanumérico. Exemplo: Eritrócitos / Leucócitos / Glicose / Ureia / Creatinina. Para o exame Hemograma, tem o resultado de vários analitos: Eritrócitos, Hemoglobina, Leucócitos, Linfócitos, etc. A maioria dos exames tem somente 1 analito, por exemplo Glicose, Colesterol Total, Uréia e Creatinina.\"\n",
    "    )\n",
    "    cd_unidade: Mapped[str | None] = column(\n",
    "        comment=\"Unidade de Medida utilizada na Metodologia do laboratório específico para analisar o exame. Alfanumérico. Exemplo: g/dL (gramas por decilitro)\"\n",
    "    )\n",
    "    de_valor_referencia: Mapped[str | None] = column(\n",
    "        comment=\"Faixa de valores de referência. Alfanumérico. Resultado ou faixa de resultados considerado normal para este analito. Exemplo para Glicose: 75 a 99\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def de_resultnum(self) -> float | None:\n",
    "        \"\"\"\n",
    "        Extrai valor numérico do resultado ou atribui códigos especiais para resultados textuais.\n",
    "        Baseado na lógica do script COVID19_Corrige_21_02.sql\n",
    "        \"\"\"\n",
    "        if not self.de_resultado:\n",
    "            return None\n",
    "\n",
    "        # Extrai valor numérico do resultado\n",
    "        numeric_match = re.search(r\"-?\\d+[,.]?\\d*\", self.de_resultado)\n",
    "        if numeric_match:\n",
    "            numeric_str = numeric_match.group().replace(\",\", \".\")\n",
    "            try:\n",
    "                return float(numeric_str)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # Aplica códigos especiais para exames COVID\n",
    "        if self.de_exame and re.search(\n",
    "            r\"(covid)|(sars.cov.2)|(corona)\", self.de_exame, re.IGNORECASE\n",
    "        ):\n",
    "            resultado_lower = self.de_resultado.lower()\n",
    "\n",
    "            if re.search(r\"detectados anticorpos\", resultado_lower):\n",
    "                return -1000.0\n",
    "            elif re.search(\n",
    "                r\"(n.o detectado)|(n.o reagente)|(negativo)|(aus.ncia de anticorpos)\",\n",
    "                resultado_lower,\n",
    "            ):\n",
    "                return -1111.0\n",
    "            elif re.search(r\"(detectado)|(reagente)|(positivo)\", resultado_lower):\n",
    "                return -1000.0\n",
    "            elif re.search(r\"(indetect.avel)|(inconclusivo)\", resultado_lower):\n",
    "                return -1234.0\n",
    "            else:\n",
    "                return -2222.0\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Relações\n",
    "    paciente: Mapped[\"Paciente\"] = backref(\"exames\")\n",
    "\n",
    "\n",
    "class Desfecho(Base):\n",
    "    \"\"\"\n",
    "    Tabela de desfechos Covid-19 FAPESP\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"desfechos\"\n",
    "\n",
    "    id_paciente: Mapped[str] = column(\n",
    "        fk(\"pacientes.id_paciente\"),\n",
    "        comment=\"Identificação única do paciente (correlaciona com o ID_PACIENTE de todos os arquivos onde aparece. 32 caracteres alfanuméricos)\"\n",
    "    )\n",
    "    id_atendimento: Mapped[str] = column(\n",
    "        comment=\"Identificação única do atendimento. Cada atendimento tem um desfecho. Correlaciona com ID_ATENDIMENTO de todas as tabelas onde aparece\"\n",
    "    )\n",
    "    dt_atendimento: Mapped[date | None] = column(\n",
    "        comment=\"Data de realização do atendimento\"\n",
    "    )\n",
    "    de_tipo_atendimento: Mapped[str] = column(\n",
    "        comment=\"Descrição do tipo de atendimento realizado. Texto livre. Exemplo: Pronto atendimento.\"\n",
    "    )\n",
    "    id_clinica: Mapped[int] = column(\n",
    "        comment=\"Identificação da clínica onde o evento aconteceu. Numérico. Exemplo: 1013\"\n",
    "    )\n",
    "    de_clinica: Mapped[str] = column(\n",
    "        comment=\"Descrição da clínica onde o evento aconteceu. Texto livre. Exemplo: Cardiologia\"\n",
    "    )\n",
    "    dt_desfecho: Mapped[date | None] = column(\n",
    "        comment=\"Data do desfecho - Nulo se DE_DESFECHO for óbito\"\n",
    "    )\n",
    "    de_desfecho: Mapped[str] = column(\n",
    "        comment=\"Descriçao do desfecho. Texto livre. Exemplo: Alta médica melhorado\"\n",
    "    )\n",
    "\n",
    "    # Relações\n",
    "    paciente: Mapped[\"Paciente\"] = backref(\"desfechos\")\n",
    "\n",
    "    __table_args__: tuple[pkc,] = (pkc(\"id_paciente\", \"id_atendimento\"),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe80313-f7f6-4dce-9e55-6eb920fa9bb1",
   "metadata": {},
   "source": [
    "## População dos bancos de dados\n",
    "\n",
    "Abaixo descrevemos a lógica para população dos bancos de dados. Os datasets que descrevem a cada tabela de cada banco de dados estão localizados em uma pasta `dataset` colocada no mesmo diretório que este notebook.\n",
    "\n",
    "```bash\n",
    "~/Public/USP/Ciência da Computação/Semestre 6/Mineração de dados/01-Introdução-Preparação de dados main*\n",
    "❄️impure ❯ exa --tree\n",
    ".\n",
    "├── datasets\n",
    "│   ├── BPSP\n",
    "│   │   ├── BPSP_Desfechos.csv\n",
    "│   │   ├── BPSP_ExamLabs.csv\n",
    "│   │   └── BPSP_Pacientes.csv\n",
    "│   ├── Einstein\n",
    "│   │   ├── Einstein_ExamLabs.csv\n",
    "│   │   └── Einstein_Pacientes.csv\n",
    "│   ├── GrupoFleury\n",
    "│   │   ├── GrupoFleury_ExamLabs.csv\n",
    "│   │   └── GrupoFleury_Pacientes.csv\n",
    "│   ├── HC\n",
    "│   │   ├── HC_ExamLabs.csv\n",
    "│   │   └── HC_Pacientes.csv\n",
    "│   └── HSL\n",
    "│       ├── HSL_Desfechos.csv\n",
    "│       ├── HSL_ExamLabs.csv\n",
    "│       └── HSL_Pacientes.csv\n",
    "└── 'Geração de Databases com SQLalchemy e PostgreSQL.ipynb'\n",
    "```\n",
    "Como se vê, os datasets encontram-se nomeados de maneira padronizada, e os nomes das colunas de suas tabelas correspondem aos nomes dados aos atributos das classes que aqui descrevem as tabelas contidas nos BDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd70006-1e3c-4501-b06c-f41d21ef60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = \"/datasets\"\n",
    "hospitals = [\"BPSP\", \"Einstein\", \"GrupoFleury\", \"HC\", \"HSL\"]\n",
    "tables_dict = {\"Pacientes\": Paciente, \"ExamLabs\": ExamLab, \"Desfechos\": Desfecho}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed38079-7d67-40d9-84e4-7e7cc8a73f84",
   "metadata": {},
   "source": [
    "### Criação do Banco de Dados\n",
    "\n",
    "As duas células seguintes executam a criação do banco de dados e dos _schemas_ para cada hospital, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26d42ef-c577-4b21-b82a-669af0e2df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13 19:50:08,403 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-13 19:50:08,403 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-13 19:50:08,404 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-13 19:50:08,405 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-13 19:50:08,406 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-13 19:50:08,406 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-13 19:50:08,407 INFO sqlalchemy.engine.Engine BEGIN (implicit; DBAPI should not BEGIN due to autocommit mode)\n",
      "2025-09-13 19:50:08,407 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS BPSP\n",
      "2025-09-13 19:50:08,408 INFO sqlalchemy.engine.Engine [generated in 0.00056s] {}\n",
      "2025-09-13 19:50:08,410 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS Einstein\n",
      "2025-09-13 19:50:08,410 INFO sqlalchemy.engine.Engine [generated in 0.00047s] {}\n",
      "2025-09-13 19:50:08,412 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS GrupoFleury\n",
      "2025-09-13 19:50:08,412 INFO sqlalchemy.engine.Engine [generated in 0.00035s] {}\n",
      "2025-09-13 19:50:08,414 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS HC\n",
      "2025-09-13 19:50:08,415 INFO sqlalchemy.engine.Engine [generated in 0.00045s] {}\n",
      "2025-09-13 19:50:08,416 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS HSL\n",
      "2025-09-13 19:50:08,417 INFO sqlalchemy.engine.Engine [generated in 0.00032s] {}\n",
      "2025-09-13 19:50:08,418 INFO sqlalchemy.engine.Engine CREATE SCHEMA IF NOT EXISTS D2\n",
      "2025-09-13 19:50:08,419 INFO sqlalchemy.engine.Engine [generated in 0.00061s] {}\n",
      "2025-09-13 19:50:08,420 INFO sqlalchemy.engine.Engine ROLLBACK using DBAPI connection.rollback(); set skip_autocommit_rollback to prevent fully\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DATABASE_URI, echo=True)\n",
    "\n",
    "with engine.connect().execution_options(isolation_level=\"AUTOCOMMIT\") as conn:\n",
    "    for hospital in hospitals + [\"D2\"]:\n",
    "        conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {hospital}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4619216d-9ad2-49e8-b72b-07b69460a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating table Pacientes from BPSP schema: 1it [00:02,  2.03s/it]\n",
      "Populating table ExamLabs from BPSP schema: 4it [09:05, 136.48s/it]\n",
      "Populating table Desfechos from BPSP schema: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_paciente', 'id_atendimento', 'dt_atendimento',\n",
      "       'de_tipo_atendimento', 'id_clinica', 'de_clinica', 'dt_desfecho',\n",
      "       'de_desfecho'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating table Desfechos from BPSP schema: 1it [00:15, 15.40s/it]\n",
      "Populating table Pacientes from Einstein schema: 1it [00:03,  3.66s/it]\n",
      "Populating table ExamLabs from Einstein schema: 2it [06:50, 205.23s/it]\n",
      "Populating table Pacientes from GrupoFleury schema: 1it [00:29, 29.09s/it]\n",
      "Populating table ExamLabs from GrupoFleury schema: 10it [37:53, 227.39s/it]\n",
      "Populating table Pacientes from HC schema: 1it [00:00,  4.27it/s]\n",
      "Populating table ExamLabs from HC schema: 2it [02:58, 89.25s/it] \n",
      "Populating table Pacientes from HSL schema: 1it [00:00,  2.45it/s]\n",
      "Populating table ExamLabs from HSL schema: 1it [01:16, 76.42s/it]\n",
      "Populating table Desfechos from HSL schema: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_paciente', 'id_atendimento', 'dt_atendimento',\n",
      "       'de_tipo_atendimento', 'id_clinica', 'de_clinica', 'dt_desfecho',\n",
      "       'de_desfecho'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating table Desfechos from HSL schema: 1it [00:02,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "def batch_insert(session: Session, hospital: str, table_name: str, table_class) -> None:\n",
    "    chunks = pd.read_csv(\n",
    "        f\"{datasets_folder}/{hospital}/{hospital}_{table_name}.csv\",\n",
    "        delimiter=\"|\",\n",
    "        encoding=\"utf-8\",\n",
    "        low_memory=False,\n",
    "        chunksize=BATCH_SIZE,\n",
    "        dtype = {'CD_Unidade': str}\n",
    "    )\n",
    "    pbar = tqdm(\n",
    "        chunks, desc=f\"Populating table {table_name} from {hospital} schema\"\n",
    "    )\n",
    "    \n",
    "    if table_name == \"Pacientes\":\n",
    "        for df in pbar:\n",
    "            df.rename(columns=normalize_column_name, inplace=True)\n",
    "            # AA_Nascimento verification. Condition 1: Value is 'AAAA' or 'YYYY'\n",
    "            is_placeholder = df['aa_nascimento'].isin(['AAAA', 'YYYY'])\n",
    "    \n",
    "            # Condition 2: Value is a 4-digit string\n",
    "            # Ensure it's a string before using .str accessor\n",
    "            is_4_digit_year = (df['aa_nascimento'].astype(str).str.isdigit()) & \\\n",
    "                              (df['aa_nascimento'].astype(str).str.len() == 4)\n",
    "    \n",
    "            # Combine conditions: A row is valid if it meets Condition 1 OR Condition 2\n",
    "            valid_mask = is_placeholder | is_4_digit_year\n",
    "    \n",
    "            df.loc[~valid_mask, 'aa_nascimento'] = None\n",
    "            df['cd_pais'] = df['cd_pais'].replace('XX', None)\n",
    "            df['cd_uf'] = df['cd_uf'].replace('UU', None)\n",
    "            df['cd_municipio'] = df['cd_municipio'].replace('MMMM', None)\n",
    "            df['cd_cepreduzido'] = df['cd_cepreduzido'].replace('CCCC', None)\n",
    "            session.execute(insert(table_class), df.to_dict('records'))\n",
    "    else:\n",
    "        result = session.execute(text('SELECT ID_Paciente FROM Pacientes'))\n",
    "        valid_patient_ids = {row[0] for row in result}\n",
    "        if table_name == \"ExamLabs\":\n",
    "            for df in pbar:\n",
    "                df.rename(columns=normalize_column_name, inplace=True)\n",
    "                df = df[df['id_paciente'].isin(valid_patient_ids)].copy()\n",
    "                df['dt_coleta'] = parse_date(df['dt_coleta'])\n",
    "                df = df.astype(object).where(pd.notna(df), None)\n",
    "                session.execute(insert(table_class), df.to_dict('records'))\n",
    "        else:\n",
    "            for df in pbar:\n",
    "                df.rename(columns=normalize_column_name, inplace=True)\n",
    "                df = df[df['id_paciente'].isin(valid_patient_ids)].copy()\n",
    "                df['dt_atendimento'] = parse_date(df['dt_atendimento'])\n",
    "                df['dt_desfecho'] = parse_date(df['dt_desfecho'])\n",
    "                df = df.astype(object).where(pd.notna(df), None)\n",
    "                session.execute(insert(table_class), df.to_dict('records'))\n",
    "\n",
    "\n",
    "for hospital in hospitals:\n",
    "    engine = create_engine(\n",
    "        DATABASE_URI,\n",
    "        connect_args={'options': f'-c search_path={hospital}'},\n",
    "    )\n",
    "\n",
    "    for table_name, table_class in tables_dict.items():\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        with Session() as session:\n",
    "            Base.metadata.create_all(engine)\n",
    "            session.commit()\n",
    "\n",
    "            try:\n",
    "                batch_insert(session, hospital, table_name, table_class)\n",
    "                session.commit()\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b687256-ced7-4b53-bc44-95f88ef9c000",
   "metadata": {},
   "source": [
    "O resultado esperado desta execução é a criação dos seguintes BDs estruturados tal qual exibe os seguinte diagrama gerado usando a ferramenta DBeaver:\n",
    "\n",
    "![Estrutura do BD, onde Pacientes figura como uma tabela associada a ExamLabs e Despachos](imgs/db_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04e2c7-e1c9-4e01-b55b-5a47f12535fe",
   "metadata": {},
   "source": [
    "# Criação de novo banco de dados para a análise de dados\n",
    "\n",
    "Em seguida, criamos um novo BD para conter dados agregados a todos os demais BDs. Isto, conforme os critérios de seleção vistos na tabela AnalisesCovid, descrita a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39390baa-1077-4703-adb5-59d4dbdcb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnaliseCovid(PacienteBase):\n",
    "    \"\"\"\n",
    "    Tabela de análises Covid-19 FAPESP\n",
    "\n",
    "    Complementa a tabela Paciente com dados relevantes sobre atendimentos,\n",
    "    exames e desfechos extraídos das tabelas ExamLabs e Desfechos para análise\n",
    "    epidemiológica de casos associados ao COVID-19\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__: str = \"AnalisesCovid\"\n",
    "    id: Mapped[int] = column(autoincrement=True, primary_key=True)\n",
    "\n",
    "    # Aggregated data\n",
    "    ID_Paciente: Mapped[str] = column(\n",
    "        comment=\"Identificação única do paciente (32 caracteres alfanuméricos)\"\n",
    "    )\n",
    "    ID_Atendimento: Mapped[str | None] = column(\n",
    "        comment=\"Identificação única do atendimento (32 caracteres alfanuméricos)\"\n",
    "    )\n",
    "    DT_Coleta: Mapped[date | None] = column(\n",
    "        comment=\"Data em que o material foi coletado para exame\"\n",
    "    )\n",
    "    DT_Atendimento: Mapped[date | None] = column(\n",
    "        comment=\"Data de realização do atendimento\"\n",
    "    )\n",
    "    DT_Desfecho: Mapped[date | None] = column(\n",
    "        comment=\"Data do desfecho do paciente (alta, óbito, etc.)\"\n",
    "    )\n",
    "    DE_Desfecho: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do desfecho do paciente (ex: 'Alta médica melhorado', 'Óbito')\"\n",
    "    )\n",
    "    DE_Exame: Mapped[str | None] = column(\n",
    "        comment=\"Descrição do exame realizado (ex: 'Teste COVID-19', 'Hemograma')\"\n",
    "    )\n",
    "    DE_Resultado: Mapped[str | None]\n",
    "\n",
    "    # Added metadata\n",
    "    DE_Classe: Mapped[str | None] = column(\n",
    "        Enum('P', 'N', name='classe_enum'),\n",
    "        comment=\"Resultado do exame COVID-19 simplificado (P - Positivo, N - Negativo, None - Outro/Indeterminado)\"\n",
    "    )\n",
    "    DE_Hospital: Mapped[str] = column(\n",
    "        comment=\"Identificação do hospital de origem dos dados (BPSP, Einstein, GrupoFleury, HC, HSL)\"\n",
    "    )\n",
    "\n",
    "class PacienteD2(Paciente):\n",
    "    de_hospital: Mapped [str]\n",
    "\n",
    "class ExamLabD2(ExamLab):\n",
    "    de_hospital: Mapped [str]\n",
    "\n",
    "class DesfechoD2(Desfecho):\n",
    "    de_hospital: Mapped [str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6f615-68ca-4a12-b600-dca4428eed55",
   "metadata": {},
   "source": [
    "## População do BD D2 com dados dos demais BDs\n",
    "\n",
    "Em seguida acessamos aos demais BDs um a um e criamos registros correspondentes no DB D2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6be02b-2dde-4dae-923f-fe247a8219ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:25:31,900 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-14 01:25:31,900 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-14 01:25:31,902 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-14 01:25:31,902 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-14 01:25:31,904 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-14 01:25:31,905 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-14 01:25:31,906 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-14 01:25:31,908 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,908 INFO sqlalchemy.engine.Engine [generated in 0.00032s] {'table_name': 'AnalisesCovid', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,912 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,912 INFO sqlalchemy.engine.Engine [cached since 0.004565s ago] {'table_name': 'pacientes', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,914 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,914 INFO sqlalchemy.engine.Engine [cached since 0.006085s ago] {'table_name': 'examlabs', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,915 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,915 INFO sqlalchemy.engine.Engine [cached since 0.007524s ago] {'table_name': 'desfechos', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,917 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,917 INFO sqlalchemy.engine.Engine [generated in 0.00037s] {'typname_1': 'sexo_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,919 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,919 INFO sqlalchemy.engine.Engine [cached since 0.001997s ago] {'typname_1': 'estado_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,920 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_type.typname \n",
      "FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace \n",
      "WHERE pg_catalog.pg_type.typname = %(typname_1)s AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-09-14 01:25:31,920 INFO sqlalchemy.engine.Engine [cached since 0.003429s ago] {'typname_1': 'classe_enum', 'nspname_1': 'pg_catalog'}\n",
      "2025-09-14 01:25:31,921 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "# Populate a new database D2 with its tables\n",
    "engine = create_engine(\n",
    "    DATABASE_URI,\n",
    "    connect_args={'options': f'-c search_path=D2'},\n",
    "    echo = True\n",
    ")\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "with Session() as session:\n",
    "    tables = [\n",
    "        AnaliseCovid.__table__,\n",
    "        PacienteD2.__table__,\n",
    "        ExamLabD2.__table__,\n",
    "        DesfechoD2.__table__,\n",
    "    ]\n",
    "    Base.metadata.create_all(engine, tables=tables)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d74be-c382-452e-b41a-225d8ea7355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Copying BPSP.Pacientes data ---\n",
      "Copied BPSP.Pacientes to d2.Pacientes\n",
      "--- Copying Einstein.Pacientes data ---\n",
      "Copied Einstein.Pacientes to d2.Pacientes\n",
      "--- Copying GrupoFleury.Pacientes data ---\n",
      "Copied GrupoFleury.Pacientes to d2.Pacientes\n",
      "--- Copying HC.Pacientes data ---\n",
      "Copied HC.Pacientes to d2.Pacientes\n",
      "--- Copying HSL.Pacientes data ---\n",
      "Copied HSL.Pacientes to d2.Pacientes\n",
      "--- Copying BPSP.ExamLabs data ---\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DATABASE_URI)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n",
    "\n",
    "    for table_name, table_class in tables_dict.items():\n",
    "        for hospital in hospitals:\n",
    "            print(f\"--- Copying {hospital}.{table_name} data ---\")    \n",
    "            columns = [\n",
    "                col for col in table_class.__table__.columns if col.name != \"id\" \n",
    "            ]\n",
    "            insert_columns = \", \".join([f'{col.name}' for col in columns])\n",
    "\n",
    "            # Apply the explicit DOUBLE CAST for Enum types\n",
    "            select_columns = \", \".join([\n",
    "                f'{col.name}::text::d2.{col.type.name}'\n",
    "                if isinstance(col.type, Enum)\n",
    "                else f'\"{col.name}\"'\n",
    "                for col in columns\n",
    "                if col.name != \"de_hospital\"\n",
    "            ])\n",
    "            \n",
    "            copy_sql = f\"\"\"\n",
    "                INSERT INTO d2.{table_name.lower()} ({insert_columns})\n",
    "                SELECT {select_columns}, '{hospital}' as de_hospital \n",
    "                FROM {hospital}.{table_name.lower()}\n",
    "            \"\"\"\n",
    "            try:\n",
    "                conn.execute(text(copy_sql))\n",
    "                print(f\"Copied {hospital}.{table_name} to d2.{table_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {hospital}.{table_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae3565d-f044-4482-9ece-8b8a8a94cbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando registros: 87303it [00:42, 2069.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificando tabela resultante ---\n",
      "   id       ID_Paciente                    ID_Atendimento  DT_Coleta  \\\n",
      "0   1  A948293FBD96829F  C385FCF6D86F8453977BCE950A2BA52D 2020-10-27   \n",
      "1   2  C2B72F3749CDEBA6  295FF00C087A8DBFF5DB8AC04A845CF4 2020-05-06   \n",
      "2   3  CA46DFD79957AB5E  0A76C55DA211F2E105DAD236F7D5882A 2020-11-03   \n",
      "3   4  A2CD4F9678833EE3  420886C1808180B44294773F0B5A5042 2020-07-14   \n",
      "4   5  17F7B03B3E18DCBE  0FF4402584C659799E96353C025650AC 2020-04-06   \n",
      "\n",
      "  DT_Atendimento DT_Desfecho                               DE_Desfecho  \\\n",
      "0     2020-10-27  2020-10-27                       Alta Administrativa   \n",
      "1     2020-05-06  2020-05-06                Alta do Pronto Atendimento   \n",
      "2     2020-09-02  2020-11-30  Transferencia para Internacao Domiciliar   \n",
      "3     2020-07-14  2020-08-09                            Alta melhorado   \n",
      "4     2020-04-06  2020-04-06                Alta do Pronto Atendimento   \n",
      "\n",
      "                               DE_Exame              DE_Resultado DE_Classe  \\\n",
      "0  Coronavirus Covid-19 - Pre Cirurgico  NAO DETECTADO (NEGATIVO)         N   \n",
      "1                  Coronavirus Covid-19             NAO DETECTADO         N   \n",
      "2                  Coronavirus Covid-19  NAO DETECTADO (NEGATIVO)         N   \n",
      "3                  Coronavirus Covid-19  NAO DETECTADO (NEGATIVO)         N   \n",
      "4                  Coronavirus Covid-19             NAO DETECTADO         N   \n",
      "\n",
      "  DE_Hospital IC_Sexo AA_Nascimento CD_Pais CD_UF           CD_Municipio  \\\n",
      "0        BPSP       M          1990      BR    SP              SAO PAULO   \n",
      "1        BPSP       F          YYYY      BR    SP              SAO PAULO   \n",
      "2        BPSP       F          YYYY      BR  None                   None   \n",
      "3        BPSP       M          YYYY      BR    SP  SAO BERNARDO DO CAMPO   \n",
      "4        BPSP       M          YYYY      BR    SP              SAO PAULO   \n",
      "\n",
      "  CD_CEPReduzido  \n",
      "0           None  \n",
      "1           None  \n",
      "2           None  \n",
      "3           None  \n",
      "4           None  \n",
      "\n",
      "Total de entradas em AnalisesCovid: 87303\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "    DATABASE_URI,\n",
    "    connect_args={'options': f'-c search_path=D2'},\n",
    ")\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "with Session() as session:\n",
    "    query = (\n",
    "        session.query(\n",
    "            PacienteD2,          # Select the entire PacienteD2 object\n",
    "            ExamLabD2.de_resultado,\n",
    "            ExamLabD2.de_resultado,\n",
    "            ExamLabD2.dt_coleta,\n",
    "            ExamLabD2.id_atendimento,\n",
    "            DesfechoD2.de_desfecho,\n",
    "            DesfechoD2.dt_desfecho,\n",
    "            DesfechoD2.dt_atendimento\n",
    "        )\n",
    "        .select_from(PacienteD2)\n",
    "        .join(ExamLabD2, PacienteD2.id_paciente == ExamLabD2.id_paciente)\n",
    "        .join(\n",
    "            DesfechoD2,\n",
    "            (PacienteD2.id_paciente == DesfechoD2.id_paciente)\n",
    "            & (ExamLabD2.id_atendimento == DesfechoD2.id_atendimento),\n",
    "        )\n",
    "        .filter(\n",
    "            ExamLabD2.de_exame.ilike(\"%covid%\")\n",
    "            | ExamLabD2.de_exame.ilike(\"%corona%\")\n",
    "            | ExamLabD2.de_exame.ilike(\"%sars%\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "    for chunk in tqdm(query.yield_per(BATCH_SIZE), desc=\"Processando registros\"):\n",
    "        temp_exam = ExamLab(\n",
    "            DE_Exame=chunk.de_exame, DE_Resultado=chunk.de_resultado\n",
    "        )\n",
    "\n",
    "        match temp_exam.de_resultnum:\n",
    "            case -1000:\n",
    "                classe = \"P\"\n",
    "            case -1111:\n",
    "                classe = \"N\"\n",
    "            case _:\n",
    "                classe = None\n",
    "\n",
    "        records.append (\n",
    "            {\n",
    "                \"id_paciente\": chunk.paciented2.id_paciente,\n",
    "                \"id_atendimento\": chunk.id_atendimento,\n",
    "                \"ic_sexo\": chunk.paciented2.ic_sexo,\n",
    "                \"aa_nascimento\": chunk.paciented2.aa_nascimento,\n",
    "                \"cd_uf\": chunk.paciented2.cd_uf,\n",
    "                \"cd_pais\": chunk.paciented2.cd_pais,\n",
    "                \"cd_municipio\": chunk.paciented2.cd_municipio,\n",
    "                \"cd_cepreduzido\": chunk.paciented2.cd_cepreduzido,\n",
    "                \"dt_atendimento\": chunk.dt_atendimento,\n",
    "                \"dt_coleta\": chunk.dt_coleta,\n",
    "                \"de_exame\": chunk.de_exame,\n",
    "                \"dt_desfecho\": chunk.dt_desfecho,\n",
    "                \"de_desfecho\": chunk.de_desfecho,\n",
    "                \"de_resultado\": chunk.de_resultado,\n",
    "                \"de_classe\": classe,\n",
    "                \"de_hospital\": chunk.paciented2.de_hospital,\n",
    "            }\n",
    "        )\n",
    "    if records:\n",
    "        session.execute(insert(AnaliseCovid), records)\n",
    "        session.commit()\n",
    "\n",
    "df = pd.read_sql_table(\"analises_covid\", engine)\n",
    "print(\"\\n--- Verificando tabela resultante ---\")\n",
    "print(df.head())\n",
    "print(f\"\\nTotal de entradas em AnalisesCovid: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
